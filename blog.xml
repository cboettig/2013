<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Lab Notebook - blog</title>
 <link href="/2013/blog.xml" rel="self"/>
 <link href="/"/>
 <updated>2015-02-25T23:05:28+00:00</updated>
 <id>http://www.carlboettiger.info/2013</id>
 <author>
   <name>Carl Boettiger</name>
   <email>cboettig@gmail.com</email>
 </author>

 
 <entry>
   <title>So, you're active on Research Gate?</title>
	 <link href="/2013/11/14/research-gate.html"/>
   <updated>2013-11-14T00:00:00+00:00</updated>
   <id>/11/14/research-gate</id>
   <content type="html">&lt;p&gt;I have occassionally been getting this question:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;So, you’re active on ResearchGate?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Sounds like being accused of some scandal, doesn’t it?&lt;/p&gt;
&lt;p&gt;I’m not generally active on it - my impression is that the open science community is mostly skeptical about ResearchGate and any other “Social Network” for scientists, largely on the grounds that “we already use the same social networks everyone else uses.” Some object on more philosophical grounds (profit, Mendeley, etc), but heck I publish in Elsevier/Springer/Wiley so I won’t preach. That’s perhaps a US/elite institution centric view though; it seems more popular with a more international audience where things like basic access to pdfs may be more of an issue. I present no data to back any if that up.&lt;/p&gt;
&lt;p&gt;Personally, it hasn’t added any value for me, in contrast to the value I get from interacting with other researchers on Github, G+ or Twitter. Still, as RG recently got $35 million from Bill Gates, they might actually build something useful. Certainly traditional publishers have left plenty of room for innovation in the space of sharing data, networking, etc. So I have a profile there to wait and see, next to a disclaimer that says “please see my website for updated information.”&lt;/p&gt;
&lt;p&gt;However, I was actually impressed by ResearchGate this morning. While I thought I had successfully blocked most of their email notifications, one this morning had successfully found the full text of a recent paper of mine (albeit a few months after it had appeared). Instead of asking me to upload something, RG was able to obtain the full text from the publisher (Springer). On so doing, it also asks me if I would like to “follow” several of the researchers I cited who are also on ResearchGate.&lt;/p&gt;
&lt;p&gt;Why is that impressive? Mendeley, for all it’s much more natural fit into most researcher’s workflows, never automatically discovers papers I publish. If I want them in my Mendeley profile, I have to add them manually. Manually maintaining profiles across different networks is so entirely a waste of time and the antithesis of a linked data web where I have already made this information machine readable that I find it the most annoying feature by far in any of these sites. Here, ResearchGate is actually doing the intelligent thing, whether by connecting my RG identity to my ORCID ID, or something more heuristic. (Google Scholar automatically adds things to my profile, but in a far less selective algorithm that can be easily gamed, see &lt;a href=&quot;http://doi.org/10.1002/asi.23056&quot;&gt;10.1002/asi.23056&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;By obtaining the full-text directly from the publisher, they show the considerable advantage of a well-funded network. Presumably this indicates that access was negotiated directly with the publisher, who agrees and even facilitates me sharing the full-text of my otherwise paywalled article on my RG profile. That’s a non-trivial contribution towards open access: Contrast this to Mendeley’s more murky policy which encourages me to provide full text access through my user profile but places the legal responsibility directly on me to confirm that this permissible, or an organization like ORCID which despite (because of?) it’s more non-profit and utilitarian values does not have permission to distribute my paywalled pdfs on my profile. (Sure, my papers on arXiv already, but that isn’t the point).&lt;/p&gt;
&lt;p&gt;Likewise, using the citation data against the RG data on which researchers have profiles shows a vaguely intelligent use of data other platforms mostly ignore (providing useful suggestions using some understanding of the academic process rather than mindless application of some friend-of-a-friend network algorithm).&lt;/p&gt;
&lt;p&gt;(The fact that RG pings unfortunate souls who might have signed up once but have no desire to see my “Activity” on RG is one of it’s potentially effective marketing but more pernicious decisions. Use does not necessarily imply trust).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Do we need a culture of Data Science in Academia?</title>
	 <link href="/2013/11/13/Data-Science-Center.html"/>
   <updated>2013-11-13T00:00:00+00:00</updated>
   <id>/11/13/Data-Science-Center</id>
   <content type="html">&lt;p&gt;Just my draft copy of a &lt;a href=&quot;http://dynamicecology.wordpress.com/2013/11/25/do-we-need-a-culture-of-data-science-in-academia-guest-post/&quot;&gt;Guest blog post&lt;/a&gt; I wrote for Dynamic Ecology.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;On Tuesday the &lt;a href=&quot;http://www.nitrd.gov/nitrdgroups/index.php?title=Data_to_Knowledge_to_Action&quot;&gt;Whitehouse Office of Science and Technology Policy&lt;/a&gt; announced the creation of a $37.8 million dollar initiative to promote a “Data Science Culture” in academic institutions, funded by the &lt;a href=&quot;http://www.moore.org/newsroom/press-releases/2013/11/12/%20bold_new_partnership_launches_to_harness_potential_of_data_scientists_and_big_data&quot;&gt;Gordon and Betty Moore Foundation&lt;/a&gt;, &lt;a href=&quot;http://www.sloan.org/fileadmin/media/files/press_releases/datascience.pdf&quot;&gt;Alfred P. Sloan Foundation&lt;/a&gt;, and hosted in centers at the universities UC Berkeley, University of Washington, and New York University. Sadly, these announcements give little description of just what such a center would do, beyond repeating the usual the hype of “Big Data.”&lt;/p&gt;
&lt;p&gt;Fernando Perez, a research scientist at UC Berkeley closely involved with the process, paints a rather more provocative picture in his own perspective on &lt;a href=&quot;http://blog.fperez.org/2013/11/an-ambitious-experiment-in-data-science.html&quot;&gt;what this initiative might mean by a “Data Science Culture.”&lt;/a&gt; Rather than motivating the need for such a Center merely by expressing terabytes in scientific notation, Perez focuses on something not mentioned in the press releases. In his view, the objective of such a center stems from the observation that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;the incentive mechanisms of academic research are at sharp odds with the rising need for highly collaborative interdisciplinary research, where computation and data are first-class citizens&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;His list of problems to be tackled by this Data Science Initiative includes some particularly catching references to issues that have raised themselves on Dynamic Ecology before:&lt;/p&gt;
&lt;!--
&gt; - An incentive structure that favors individualism, hyper-specialization and &quot;novelty&quot; to a toxic extreme
--&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;people grab methods like shirts from a rack, to see if they work with the pants they are wearing that day&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;methodologists tend to only offer proof-of-concept, synthetic examples, staying largely shielded from real-world concerns&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Well that’s a different tune than the usual big data hype&lt;a href=&quot;#fn1&quot; class=&quot;footnoteRef&quot; id=&quot;fnref1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. While it is easy to find anecdotes that support each of these charges, it is more difficult to assess just how rare or pervasive they really are. Though these are not new complaints among ecologists, the solutions (or at least antidotes) proposed in a Data Science Culture given a rather different emphasis. At first glance, the Data Science Culture sounds like the more familiar call for an interdisciplinary culture, emphasizing that the world would be a better place if only domain scientists learned more mathematics, statistics and computer science. It is not.&lt;/p&gt;
&lt;h5 id=&quot;the-problem-part-1-statistical-machismo&quot;&gt;the problem, part 1: &lt;a href=&quot;http://dynamicecology.wordpress.com/2012/09/11/statistical-machismo/&quot;&gt;statistical machismo&lt;/a&gt;?&lt;/h5&gt;
&lt;p&gt;As to whether ecologists choose methods to match their pants, we have at least some data beyond anecdote. A survey earlier this year by Joppa et al. &lt;a href=&quot;http://doi.org/10.1126/science.1231535&quot;&gt;(2013) &lt;em&gt;Science&lt;/em&gt;&lt;/a&gt;) has indeed shown that most ecologists select methods software guided primarily by concerns of fashion (in other words, whatever everybody else uses). The recent expansion of readily available statistical software has greatly increased the number of shirts on the rack. Titles in &lt;em&gt;Ecology&lt;/em&gt; reflect the trend of rising complexity in ecological models, such as &lt;a href=&quot;http://doi.org/10.1890/10-1124.1&quot;&gt;Living Dangerously with big fancy models&lt;/a&gt; and &lt;a href=&quot;http://doi.org/10.1890/10-0052.1&quot;&gt;Are exercises like this a good use of anybody’s time?&lt;/a&gt;). Because software enables researchers to make use of methods without the statistical knowledge of how to implement them from the ground up, many echo the position so memorably &lt;a href=&quot;http://press.princeton.edu/titles/8348.html&quot;&gt;articulated by Jim Clark&lt;/a&gt; that we “handing guns to children.” This belittling position usually leads to a call for improved education and training in mathematical and statistical underpinnings (see each of the 9 articles in another &lt;a href=&quot;http://doi.org/10.1890/08-1402.1&quot;&gt;&lt;em&gt;Ecology&lt;/em&gt; Forum&lt;/a&gt; on this topic), or the occassional wistful longing for a simpler time.&lt;/p&gt;
&lt;h5 id=&quot;the-solution-part-1-data-publication&quot;&gt;the solution, part 1: data publication?&lt;/h5&gt;
&lt;p&gt;What is most interesting to me in Perez’s perspective on the Data Science Institute in an emphasis on changing &lt;em&gt;incentives&lt;/em&gt; more than changing &lt;em&gt;educational&lt;/em&gt; practices. Perez characterizes the fundamental objective of the initiative as a &lt;em&gt;cultural shift in which&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“The creation of usable, robust computational tools, and the work of data acquisition and analysis must be treated as equal partners to methodological advances or domain-specific results”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;While this does not tackle the problem of misuse or misinterpretation of statistical methodology head-on, I believe it is a rather thought-provoking approach to mitigate the consequences of mistakes or limiting assumptions. By atomizing the traditional publication into such component parts: data, text, and software implementation, it becomes easier to recognize each for it’s own contributions. A brilliantly executed experimental manipulation need not live or die on some minor flaw in a routine statistical analysis when the data is a product in its own right. Programmatic access to raw data and computational libraries of statistical tools could make it easy to repeat or alter the methods chosen by the original authors, allowing the consequences of these mistakes to be both understood and corrected. In the current system in which access to the raw data is rare, statistical mistakes can be difficult to detect and even harder to remedy. This in turn places a high premium on the selection of appropriate statistical methods, while putting little selective pressure on the details of the data management or implementation of those methods. Allowing the data to stand by itself places a higher premium on careful collection and annotation of data (e.g. the adoption of metadata standards). To the extent that misapplication of statistical and modeling approaches could place a substantial error rate on the literature (&lt;a href=&quot;http://www.economist.com/news/briefing/21588057-scientists-think-science-self-correcting-alarming-degree-it-not-trouble?fsrc=scn/tw_ec/trouble_at_the_lab&quot;&gt;Economist&lt;/a&gt;, &lt;a href=&quot;http://doi.org/10.1371/journal.pmed.0020124&quot;&gt;Ioannidis 2005&lt;/a&gt;), independent data publication might be an intriguing antidote.&lt;/p&gt;
&lt;!--
Data scales in a way that publications do not, even (or rather, especially) within a particular sub-domain.  Given a single paper on a topic, it is much easier to read the conclusion than replicate it from the data.  Given 1000 papers on the topic vs having the underlying data in a standardized form, it becomes easier to replicate the analyses. Surely that would just lead to nonsense, given the idiosyncrasies of each different experiment that were never meant to be compared in that way?  Surely only by carefully reading not only each paper, but each supplement, can we really understand what was done well enough to replicate or re-analyze it?  Yet we cite papers as if they have demonstrated something in far more generality than all that.   

--&gt;
&lt;h5 id=&quot;the-problem-part-2-junk-software&quot;&gt;the problem, part 2: junk software&lt;/h5&gt;
&lt;p&gt;As Perez is careful to point out, those implementing and publishing methods aren’t helping either. Unreliable, inextensible and opaque computational implementations act both as barriers to adoption and validation. Trouble with scientific software has been well recognized by the literature (e.g. &lt;a href=&quot;http://doi.org/10.1038/467775a&quot;&gt;Merali (2010), &lt;em&gt;Nature&lt;/em&gt;&lt;/a&gt;, &lt;a href=&quot;http://doi.org/10.1038/nature10836&quot;&gt;Inces et al. (2012), &lt;em&gt;Nature&lt;/em&gt;&lt;/a&gt;), the news (&lt;a href=&quot;http://www.timeshighereducation.co.uk/news/save-your-work-give-software-engineers-a-career-track/2006431.article&quot;&gt;Times Higher Education&lt;/a&gt;) and funding agencies (&lt;a href=&quot;http://www.nsf.gov/pubs/2013/nsf13525/nsf13525.htm&quot;&gt;National Science Foundation&lt;/a&gt;). While it is difficult to assess the frequency of software bugs that may really alter the results (though see Inces et al.), designs that will make software challenging or impossible to maintain, scale to larger tasks or extend as methods evolve are more readily apparent. Cultural challenges around software run as deep as they do around data. When Mozilla’s Science Lab &lt;a href=&quot;http://doi.org/10.1038/501472a&quot;&gt;undertook a review of code&lt;/a&gt; associated with scientific publications, they took some criticism from other &lt;a href=&quot;http://simplystatistics.org/2013/09/26/how-could-code-review-discourage-code-disclosure-reviewers-with-motivation/&quot;&gt;advocates&lt;/a&gt; of publishing code. I encountered this first hand in replies from authors, editors and reviewers on my own blog post &lt;a href=&quot;http://carlboettiger.info/2013/06/13/what-I-look-for-in-software-papers.html&quot;&gt;suggesting we raise the bar&lt;/a&gt; on the review of methodological implementations. Despite disagreement about where that bar should be, I think we all felt the community could benefit from clearer guidance or consensus on how to review papers in which the software implementation plays an essential part and contribution.&lt;/p&gt;
&lt;h5 id=&quot;the-solution-part-2-software-publication&quot;&gt;the solution, part 2: software publication?&lt;/h5&gt;
&lt;p&gt;As in the case of data, educational practices are the route usually suggested to address better programming practices, and no doubt these are important. Once again though, it is interesting to think how a higher incentive on such research products might also improve their quality, or at least facilitate distilling the good from the bad from the ugly, more easily. Yet in this case, I think there is a potential downside as well.&lt;/p&gt;
&lt;h6 id=&quot;or-not&quot;&gt;Or not?&lt;/h6&gt;
&lt;p&gt;While widespread recognition of its importance will no doubt help bring us faster software, fewer bugs and more user-friendly interfaces, it may do more harm than good. Promotion of software as a product can lead to empire-building, for which ESRI’s ArcGIS might be a poster child. The scientific concepts become increasingly opaque, while training in a conceptually rich academic field gives way to more mindless training in the user interface of a single giant software tool. I believe that good scientific software should be modular – small code bases that can be easily understood, inter-operable, and perform a single task well (the Unix model). This lets us build more robust computational infrastructure tailored to the problem at hand, just as individual Lego bricks may be assembled and reassembled. Unfortunately, I do not see how recognition for software products would promote small modules over vast software platforms, or interoperability with other software instead of an exclusive walled garden.&lt;/p&gt;
&lt;!-- include image of lego brick tower?--&gt;
&lt;h4 id=&quot;so-change-incentives-how&quot;&gt;So, change incentives &lt;em&gt;how&lt;/em&gt;?&lt;/h4&gt;
&lt;p&gt;If this provides some argument as to why one might want to change incentives around data and software publication, I have said nothing to suggest how. After all, as ecologists we’re trained to reflect on the impact a policy would have, not advocate for what should be done about it. If the decision-makers agree about the effects of the given incentives, then choosing what to reward should be easier.&lt;/p&gt;
&lt;!--
#### Data Science Culture is Data Sharing Culture? 

In raising these questions, Perez brings the role of a Data Science Institute down from the clouds of superficial pattern-finding in astronomically large data sets that bear no resemblance to what most of us work on, and places front and center the challenges of designing, selecting, implementing and interpreting the richer statistical analyses we face each day. In the process of bolstering the data and methodology upon which we base research today, we may open up the doors to better, faster, and bigger science tomorrow.  

--&gt;
&lt;section class=&quot;footnotes&quot;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&quot;fn1&quot;&gt;&lt;p&gt;Probably for reasons discussed &lt;a href=&quot;http://dynamicecology.wordpress.com/2013/11/07/the-one-true-route-to-good-science-is/comment-page-1/#comment-20373&quot;&gt;recently on Dynamic Ecology&lt;/a&gt; about politicians and dirty laundry.&lt;a href=&quot;#fnref1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
 </entry>
 
 <entry>
   <title>Is it time to retire Pagel's lambda?</title>
	 <link href="/2013/10/11/is-it-time-to-retire-pagels-lambda.html"/>
   <updated>2013-10-11T00:00:00+00:00</updated>
   <id>/10/11/is-it-time-to-retire-pagels-lambda</id>
   <content type="html">&lt;p&gt;Pagel’s &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt; (lambda), introduced in &lt;a href=&quot;http://doi.org/10.1038/44766&quot; title=&quot;Inferring the historical patterns of biological evolution. in Nature.&quot;&gt;Pagel 1999&lt;/a&gt; as a potential measure of “phylogenetic signal,” the extent to which correlations in traits reflect their shared evolutionary history (as approximated by Brownian motion).&lt;/p&gt;
&lt;p&gt;Numerous critiques and ready alternatives have not appeared to decrease it’s popularity. There are many issues with the statistic, some of which I attempt to summarise below.&lt;/p&gt;
&lt;p&gt;The &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt; statistic is defined by the Brownian motion model together with a transformation of the branch lengths: multiply all internal branches by &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt;. The motivation for the definition is obvious: &lt;span class=&quot;math&quot;&gt;\(\lambda = 1\)&lt;/span&gt; the tree is unchanged and the model equivalent to Brownian motion, while for &lt;span class=&quot;math&quot;&gt;\(\lambda = 0\)&lt;/span&gt; the tree becomes a star phylogeny and the model is equivalent to completely independent random walks. &lt;span class=&quot;math&quot;&gt;\(0 &amp;lt; \lambda &amp;lt; 1\)&lt;/span&gt; provides an intermediate range where the correlations are weaker than expected.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem 1: It is biological nonsense to treat tips different from other edges.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;All other problems arise from this. While it is okay that a statistic does not have a corresponding evolutionary model, being part of an explicit model might have helped avoid this sillyness. Technically &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt; is a model, but one that treats evolution along “tips” as special, as if evolution should follow completely different rules for a species alive today relative to it’s former evolutionary history. Sounds almost creationist.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem 2: The statistic doesn’t measure what is says it measures.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To demonstrate this, we can consider two cases in which phylogeny has the identical effect of explaining trait correlations, and yet have very different lambdas. Consider that Researcher 1 examines the phylogeny in Figure 1 and estimates very little phylogenetic signal, &lt;span class=&quot;math&quot;&gt;\(\lambda = 0.1\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(ape)
&lt;span class=&quot;kw&quot;&gt;cat&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;(((A_sp:10,B_sp:10):1,C_sp:11):1,D_sp:12);&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;file =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;ex.tre&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;sep =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;)
ex &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;read.tree&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;ex.tre&amp;quot;&lt;/span&gt;)
&lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(ex)&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&quot;http://farm4.staticflickr.com/3708/10715190003_f2f21044be_o.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;figcaption&gt;Figure 1&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Now Researcher 2 discovers closely related sister species of some of the taxa originally studied, as in Figure 2.&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;cat&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;((((A_sp:1, A2_sp:1):9,(B_sp:1, B2_sp:1):9):1,(C_sp:1, C2_sp:1):10):1,(D_sp:1, D2_sp:1):11);&amp;quot;&lt;/span&gt;, 
    &lt;span class=&quot;dt&quot;&gt;file =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;ex2.tre&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;sep =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;)
ex2 &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;read.tree&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;ex2.tre&amp;quot;&lt;/span&gt;)
&lt;span class=&quot;kw&quot;&gt;plot&lt;/span&gt;(ex2)&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&quot;http://farm6.staticflickr.com/5482/10715001046_f914f6ecee_o.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;figcaption&gt;Figure 2&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;There traits of sister taxa are very similar (indeed let us assume the sister species are hard to distinguish morphologically - perhaps why they were overlooked by Researcher 1). The OU or BM model estimates made by researcher 1 will closely agree with with those of Researcher 1, since the sister taxa have quite similar traits. Yet the &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt; estimates differs greatly – all of a sudden the phylogenetic signal must be quite high!&lt;/p&gt;
&lt;p&gt;And yet the underlying evolutionary process by which we have simulated the data has been unchanged! The difference arises because what formerly appeared as long tips have become short tips. How do we intepret a metric that depends so heavily on whether or not all sister species are present in the data? As noted, this problem does not impact other phylogenetic comparative methods to nearly the same extent.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem 3&lt;/strong&gt; The statistic has no notion of timescale or depth in the phylogeny.&lt;/p&gt;
&lt;p&gt;In &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt; (and other definitions such as Blomberg’s K), phylogenetic signal is an all-or-nothing proposition. If we find that really recently diverged species that happen to resemble each-other, while species that have diverged for longer than, say, a couple million years show no correlation – is this phylogenetic signal or not? This ‘extinction’ of phylogenetic signal as we go far enough back in time seems like a biologically reasonable concept that is perfectly well expressed in the &lt;span class=&quot;math&quot;&gt;\(\alpha\)&lt;/span&gt; parameter of the OU model, but is lost in the consideration of &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt;. If folks really want to estimate a continuous quantity to measure phylogenetic signal, I suggest &lt;span class=&quot;math&quot;&gt;\(\alpha\)&lt;/span&gt; is a far more meaningful number (note that it has units! (1/time or 1/branch length)).&lt;/p&gt;
&lt;p&gt;Consider the returning force alpha in the OU model (i.e. stabilizing selection). When alpha is near zero, the model is essentially Brownian, (i.e. ‘strong phylogenetic signal,’ where more recently diverged species are more similar on average than distantly related ones). When alpha is very large, traits reflect the selective constraint of the environment rather than their history, and so recently diverged species are no more or less likely to be similar than distant ones (provided all species in question are under the same OU model / same selection strength for the trait in question). The size of alpha gives the timescale over which ‘phylogenetic signal’ is lost (in units of the branch length). Two very recently diverged sister-taxa may thus show some phylogenetic correlation because their divergence time is of order 1/alpha, while those with longer divergence times act phylogeneticly independent, such as in our Figure 2 above. I find this an imperfect but reasonable meaning of phylogenetic signal.&lt;/p&gt;
&lt;p&gt;If we restrict &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt; to be strictly 1 or 0 these problems are alliviated, though then it is unnessary to define the statistic as such as we may instead consider a star tree (sometimes called the “white noise” model of evolution).&lt;/p&gt;
&lt;h4 id=&quot;other-such-statistics&quot;&gt;other such statistics&lt;/h4&gt;
&lt;p&gt;Pagel’s &lt;span class=&quot;math&quot;&gt;\(\delta\)&lt;/span&gt; is a transformation on node depth, which is again problematic as there is no meaningfully consistent way to describe what is a node (think about deep speciation events with no present day ancestor.) I believe &lt;span class=&quot;math&quot;&gt;\(\kappa\)&lt;/span&gt; would also be problematic to interpret as it is a nonlinear transform of branch length – raises branch length to a power – and thus would have a rather different effect depending on the units in which branch length were measured. (For instance, consider the case where the tree is scaled to length unity, so all branch lengths are less than one and thus become shorter with large exponents, vs one in which lengths are all larger than one). Fortunately these statistics are far less popular than &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Reflections on the Mozilla Science Code Review Pilot</title>
	 <link href="/2013/09/25/mozilla-software-review.html"/>
   <updated>2013-09-25T00:00:00+00:00</updated>
   <id>/09/25/mozilla-software-review</id>
   <content type="html">&lt;p&gt;I was recently interviewed a &lt;em&gt;Nature&lt;/em&gt; senior reporter &lt;a href=&quot;http://twitter.com/erica_check&quot;&gt;Erika Check Hayden&lt;/a&gt; on the subject of the scientific &lt;a href=&quot;http://kaythaney.com/2013/08/08/experiment-exploring-code-review-for-science/&quot;&gt;code review project&lt;/a&gt; being conducted by &lt;a href=&quot;https://wiki.mozilla.org/ScienceLab&quot;&gt;Mozilla Science Lab&lt;/a&gt;. The piece appears in this week’s issue, &lt;a href=&quot;http://doi.org/10.1038/501472a&quot; title=&quot;Mozilla plan seeks to debug scientific code&quot;&gt;Hayden 2013&lt;/a&gt;. &lt;a href=&quot;http://carlboettiger.info/2013/06/13/what-I-look-for-in-software-papers.html&quot;&gt;My blog post&lt;/a&gt; sharing my own approach to code review is mentioned at the beginning of the article, though it is rather Roger Peng’s comments at the end that have stirred &lt;a href=&quot;https://twitter.com/Erika_Check/status/382911015358181376/photo/1&quot;&gt;some interesting discussion&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Roger raises two concerns. First, that increased scrutiny will discourage researchers from sharing code, (which, right or wrong, remains a voluntary choice in most journals):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;One worry I have is that, with reviews like this, scientists will be even more discouraged from publishing their code&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;and second, that code review does not focus on what matters mosts:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We need to get more code out there, not improve how it looks&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(Erika provides a bit more context to Roger’s comments below).&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;
&lt;p&gt;
&lt;a href=&quot;https://twitter.com/ctitusbrown&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;ctitusbrown&quot;&gt;@ctitusbrown&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/cboettig&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;cboettig&quot;&gt;@cboettig&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/kaythaney&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;kaythaney&quot;&gt;@kaythaney&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/nickbarnes&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;nickbarnes&quot;&gt;@nickbarnes&lt;/span&gt;&lt;/a&gt; see whole &lt;a href=&quot;https://twitter.com/simplystats&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;simplystats&quot;&gt;@simplystats&lt;/span&gt;&lt;/a&gt; quote on prof. code review discouraging sharing &lt;a href=&quot;http://t.co/pNQWT9Safz&quot;&gt;pic.twitter.com/pNQWT9Safz&lt;/a&gt;
&lt;/p&gt;
— Erika Check Hayden (&lt;span class=&quot;citation&quot; data-cites=&quot;Erika_Check&quot;&gt;@Erika_Check&lt;/span&gt;) &lt;a href=&quot;https://twitter.com/Erika_Check/statuses/382911015358181376&quot;&gt;September 25, 2013&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;The &lt;em&gt;Nature&lt;/em&gt; News piece thus nails a central tension in the community between promoting higher standards for code (A position exemplified in an earlier &lt;em&gt;Nature&lt;/em&gt; column titled &lt;a href=&quot;http://doi.org/10.1038/467775a&quot; title=&quot;Merali 2010, Nature&quot;&gt;“Computational Science … Error: Why scientific programming does not compute”&lt;/a&gt;, and more recently in &lt;em&gt;Science&lt;/em&gt; by &lt;a href=&quot;http://doi.org/10.1126/science.1231535&quot; title=&quot;Joppa et al. 2013, &amp;#39;Troubling Trends in Scientific Software Use&amp;#39;&quot;&gt;Joppa &lt;em&gt;et al.&lt;/em&gt; 2013&lt;/a&gt;, which explicitly calls for peer review of scientific software) vs promoting more widespread sharing of software (as exemplified by Nick Barnes piece in the same issue, &lt;a href=&quot;http://doi.org/10.1038/467753a&quot; title=&quot;Barnes 2010, Nature&quot;&gt;“Publish your computer code: it is good enough”&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The arguments made in each of the perspectives are excellent, and should be required reading for anyone interested in the subject. In addition to the shorter comment by Barnes, I also recommend the more recent &lt;em&gt;Nature&lt;/em&gt; perspective, &lt;a href=&quot;http://doi.org/10.1038/nature10836&quot; title=&quot;Ince et al. 2012, Nature&quot;&gt;The Case for Open Computer Programs&lt;/a&gt;, which lays out the argument and modest practical recommendations (that have largely been ignored as far as I can tell) just brilliantly. In particular, I think they nail the issue of why describing the algorithm or providing pseudo-code is not a satisfactory description of the method.&lt;/p&gt;
&lt;p&gt;However, I also think the tension between review and sharing is somewhat artificial. While each of these positions emphasizes the need to share source-code, the call for code review by Merali, Joppa et al (or in my own blog post mentioned earlier), focus on &lt;em&gt;scientific software&lt;/em&gt; aimed at reuse by others. The concerns voiced in Roger Peng’s comments and echoed by Nick Barnes focus on another class of code entirely – code associated with a particular research publication that would primarily serve only to document and support those results, rather than be readily adapted to other uses.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;
&lt;p&gt;
&lt;a href=&quot;https://twitter.com/cboettig&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;cboettig&quot;&gt;@cboettig&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/ctitusbrown&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;ctitusbrown&quot;&gt;@ctitusbrown&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/kaythaney&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;kaythaney&quot;&gt;@kaythaney&lt;/span&gt;&lt;/a&gt; but far more important to get code out than to get it “right”, IYSWIM.
&lt;/p&gt;
— Nick Barnes (&lt;span class=&quot;citation&quot; data-cites=&quot;nickbarnes&quot;&gt;@nickbarnes&lt;/span&gt;) &lt;a href=&quot;https://twitter.com/nickbarnes/statuses/382746748135174144&quot;&gt;September 25, 2013&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;h3 id=&quot;classes-of-code-snippets-vs-software&quot;&gt;Classes of Code: Snippets vs Software&lt;/h3&gt;
&lt;p&gt;For me, the crux of these concerns lies in the difference between “software papers”&lt;a href=&quot;#fn1&quot; class=&quot;footnoteRef&quot; id=&quot;fnref1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; and papers which merely use code in some element of the methodology. The Mozilla study focused exclusively on code appearing in the full-text of publications in PLoS Computational Biology. Though I am pleased to see the Science Lab tackle the issue of software review and bring the expertise of their professional software developers to bear on scientific code, this is perhaps not the kind of code I would have chosen to focus on (something I shared with the team early on in seeing the announcement).&lt;/p&gt;
&lt;p&gt;Without knowing which papers are included it is of course difficult to say to much. But knowing that the code appears in the full text of the papers themselves, we can assume that it is not a complete software package intended for reuse by other researchers. Using code within the body of a manuscript implies the intent to communicate methodology more concisely and precisely than might be done in prose; in much the same manner that we use equations in place of prose. This is an important development in scientific communication, but is also rather distinct from the use of code in other contexts, in which the code itself is meant to be read primarily by machines. It is code that is already intended to help &lt;em&gt;explain&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Code included in appendices to scientific papers is meant rather to &lt;em&gt;document&lt;/em&gt; exactly what has been done, in a manner that assists replication, and may require considerable effort to decipher exactly what is being done. Instead, it merely supports the more readable but less precise description and potentially the pseudo-code that would appear in the body text.&lt;/p&gt;
&lt;p&gt;Code intended for reuse as research software (in software papers) is another class entirely. Ostensibly, the user never needs to see the code itself, but only interact with the user interface or end-user functions (API) provided. Code that is written clearly and concisely still has value – helping identify bugs and facilitating future researcher-developers extending the software, but most of it’s functionality can be accessed and assessed without looking at the source. I think it is in this kind of review that we as a researcher-developer community could learn the most from the Mozilla software engineering experts.&lt;/p&gt;
&lt;p&gt;I believe the most important focus of code review is in scientific software rather than in code snippets. And in reviewing software, I think all of the most important elements do not actually involve reading the source code at all (as I discuss in my &lt;a href=&quot;http://carlboettiger.info/2013/07/09/reviewing-software-revisited.html&quot;&gt;revised position on reviewing software papers&lt;/a&gt;), but rather in establishing that the software behaves as expected and follows software development practices that make it more sustainable, such as hosting in a software repository, version control, or example input and output.&lt;/p&gt;
&lt;h3 id=&quot;code-vanity&quot;&gt;Code vanity?&lt;/h3&gt;
&lt;p&gt;Roger’s second comment appears more dismissive of code review than I think it actually is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“We need to get more code out there, not improve how it looks.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;
&lt;p&gt;
&lt;a href=&quot;https://twitter.com/kaythaney&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;kaythaney&quot;&gt;@kaythaney&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/ctitusbrown&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;ctitusbrown&quot;&gt;@ctitusbrown&lt;/span&gt;&lt;/a&gt; yup, ‘pretty’ is dismissive terminology, though possibly short-hand for ‘human-readable’ not just ‘machine-readable’
&lt;/p&gt;
— Carl Boettiger (&lt;span class=&quot;citation&quot; data-cites=&quot;cboettig&quot;&gt;@cboettig&lt;/span&gt;) &lt;a href=&quot;https://twitter.com/cboettig/statuses/382905327013728256&quot;&gt;September 25, 2013&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;Most modern languages include &lt;a href=&quot;http://en.wikipedia.org/wiki/Syntactic_sugar&quot;&gt;syntactic sugar&lt;/a&gt;: ways of expressing commands that are more easily interpretable to human readers. For instance, in C, &lt;code&gt;a[i]&lt;/code&gt; is syntactic sugar for &lt;code&gt;*(a+i)&lt;/code&gt;. Higher-level languages are in some ways all sugar around existing lower-level libraries.&lt;a href=&quot;#fn2&quot; class=&quot;footnoteRef&quot; id=&quot;fnref2&quot;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; Like good mathematical notation or good prose, this is not just about being ‘pretty’, but being more effective in communicating with humans. Certainly this is something we can improve upon as researchers, but it is perhaps not the best starting point.&lt;/p&gt;
&lt;h3 id=&quot;share-first-fix-later&quot;&gt;Share first, fix later&lt;/h3&gt;
&lt;p&gt;If code review should apply to all levels of code or be reserved for scientific software may still be an open question. What we should be able to agree on is in the publishing of code in the first place:&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;
&lt;p&gt;
&lt;a href=&quot;https://twitter.com/cboettig&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;cboettig&quot;&gt;@cboettig&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/kaythaney&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;kaythaney&quot;&gt;@kaythaney&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/nickbarnes&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;nickbarnes&quot;&gt;@nickbarnes&lt;/span&gt;&lt;/a&gt; I think code sharing should be mandatory &lt;em&gt;shrug&lt;/em&gt;. It&#39;s part of the methods. I reject papers w/o it.
&lt;/p&gt;
— Titus Brown (&lt;span class=&quot;citation&quot; data-cites=&quot;ctitusbrown&quot;&gt;@ctitusbrown&lt;/span&gt;) &lt;a href=&quot;https://twitter.com/ctitusbrown/statuses/382903924253929472&quot;&gt;September 25, 2013&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;It continues to surprise me how few journals require code deposition. &lt;em&gt;Science&lt;/em&gt; explicitly &lt;a href=&quot;http://doi.org/10.1126/science.1203354&quot;&gt;adopted a new policy in 2011&lt;/a&gt; stating&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Science&lt;/em&gt; is extending our data access requirement listed above to include computer codes involved in the creation or analysis of data&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;which asks that the data be placed in a appropriate permanent repository or otherwise placed in the supplementary materials (see &lt;a href=&quot;http://www.sciencemag.org/site/feature/contribinfo/prep/gen_info.xhtml#dataavail&quot;&gt;information for authors&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Yet I have not seen code provided for any analysis I have read in Science since 2011. Either we have a very different understanding of what it means to use computer codes in the analysis of data or &lt;em&gt;Science&lt;/em&gt; grossly neglects its own policy.&lt;a href=&quot;#fn3&quot; class=&quot;footnoteRef&quot; id=&quot;fnref3&quot;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; Not to pick on them of course, few other journals have explicitly adopted such a policy.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;
&lt;p&gt;
.&lt;a href=&quot;https://twitter.com/cboettig&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;cboettig&quot;&gt;@cboettig&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/kaythaney&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;kaythaney&quot;&gt;@kaythaney&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/nickbarnes&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;nickbarnes&quot;&gt;@nickbarnes&lt;/span&gt;&lt;/a&gt; As one of my grad students said to me, “I don&#39;t understand why ‘must share code’ is a radical opinion.”
&lt;/p&gt;
— Titus Brown (&lt;span class=&quot;citation&quot; data-cites=&quot;ctitusbrown&quot;&gt;@ctitusbrown&lt;/span&gt;) &lt;a href=&quot;https://twitter.com/ctitusbrown/statuses/382904483102982145&quot;&gt;September 25, 2013&lt;/a&gt;
&lt;/blockquote&gt;
&lt;p&gt;Nick Barnes suggests that this alone may be enough to improve code quality:&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;
&lt;p&gt;
&lt;a href=&quot;https://twitter.com/cboettig&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;cboettig&quot;&gt;@cboettig&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/ctitusbrown&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;ctitusbrown&quot;&gt;@ctitusbrown&lt;/span&gt;&lt;/a&gt; &lt;a href=&quot;https://twitter.com/kaythaney&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;kaythaney&quot;&gt;@kaythaney&lt;/span&gt;&lt;/a&gt; require sharing. Pride will then rapidly lead to review and other improvement techniques.
&lt;/p&gt;
— Nick Barnes (&lt;span class=&quot;citation&quot; data-cites=&quot;nickbarnes&quot;&gt;@nickbarnes&lt;/span&gt;) &lt;a href=&quot;https://twitter.com/nickbarnes/statuses/382755320143282176&quot;&gt;September 25, 2013&lt;/a&gt;
&lt;/blockquote&gt;
&lt;p&gt;Certainly it will help, though not enough if the state of open source scientific software is any indication (Nick does acknowledge a rather geological notion of ‘rapid’). Smaller codes used in particular analyses will certainly feel this pressure more, as they will be easier to scrutinize.&lt;/p&gt;
&lt;h3 id=&quot;so-what-might-we-learn-from-the-mozilla-code-review&quot;&gt;So what might we learn from the Mozilla Code review?&lt;/h3&gt;
&lt;p&gt;Focusing on code appearing in-line in papers certainly addresses a different beast than large scientific software packages intended for reuse. As Roger observed, we will likely learn that scientists aren’t software engineers. We may learn how to use code to communicate more effectively. We may learn some lessons that apply for larger codebases involved in scientific software, but I think there the problem are often outside of the individual lines of code themselves and arise from other development practices.&lt;/p&gt;
&lt;p&gt;Still, learning how to do code review at all would be an invaluable start. As the discussion on my own post on the subject made clear, we researchers have no training in this practice. The Mozilla study would give the first taste. I only hope they turn there attention next to larger scientific software that lives outside of the publications themselves and is intended at re-purposing and reuse. Meanwhile, I also hope journals will become more serious about recognizing code as methods, as they have started to do with data.&lt;/p&gt;
&lt;section class=&quot;footnotes&quot;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&quot;fn1&quot;&gt;&lt;p&gt;which I define as papers primarily aimed at promoting the reuse of a particular codebase and providing an indexed citation target to credit the work.&lt;a href=&quot;#fnref1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn2&quot;&gt;&lt;p&gt;It is frequently argued that ideal code should be ‘self-documenting’, with syntax so precise that no other explanation of the function is necessary. While I think this is an admirable ideal, it should never be a substitute for actually providing prose documentation as well. I find we too easily decieve ourselves as to just how self-documenting our own code really is (it’s all so obvious at the time, right?).&lt;a href=&quot;#fnref2&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn3&quot;&gt;&lt;p&gt;From my reading it appears that &lt;em&gt;Science&lt;/em&gt; requirements are intentionally too vague on this issue, stating: “All computer codes involved in the creation or analysis of data must also be available to any reader of Science.” It is unclear if ‘available on request’ is considered appropriate for code, though it is explicitly not acceptable for data: “we have therefore required authors to enter into an archiving agreement, in which the author commits to archive the data on an institutional Web site, with a copy of the data held at Science”, and the editorial makes it clear that “the data access requirement … includes computer codes”. Meanwhile all studies involving ‘requests for data’ have shown a return rate of substantially less than a 100% (usually less than 20%, e.g. &lt;a href=&quot;http://doi.org/10.1371/journal.pbio.1001636&quot;&gt;this recent study&lt;/a&gt;). If that was a viable option we could just publish abstracts and have papers available on request too. If you need to know who wants your data, why not do the same for papers?&lt;a href=&quot;#fnref3&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
 </entry>
 
 <entry>
   <title>Forking The R Journal</title>
	 <link href="/2013/07/10/forking-the-R-journal.html"/>
   <updated>2013-07-10T00:00:00+00:00</updated>
   <id>/07/10/forking-the-R-journal</id>
   <content type="html">&lt;p&gt;All I really wanted to do is cite a paper in &lt;em&gt;the R Journal&lt;/em&gt;, which is peer-reviewed, open access (CC-BY), LaTeX based and without author charges. Sure, I could do that already, but I like being able to programmatically generate citation metadata from a URL – we do have this thing called the internet now, and citations are just links, right? Unfortunately, nice as it is, the R journal doesn’t have HTML landing pages for articles that embed the metadata.&lt;/p&gt;
&lt;p&gt;This makes it harder for Google Scholar to index the articles, and means that we cannot extract citation metadata from the URL using a tool like &lt;a href=&quot;http://greycite.knowledgeblog.org&quot;&gt;greycite&lt;/a&gt;. Until now.&lt;/p&gt;
&lt;p&gt;I wrote to Editor-in-Chief Hadley Wickam about this, who responded in the best way possible: making the &lt;a href=&quot;ihttps://github.com/rjournal/rjournal.github.io&quot;&gt;journal website’s Github repository&lt;/a&gt; public. A fork and a little hacking later, and voila, we have html landing pages for &lt;em&gt;the R Journal&lt;/em&gt; with embedded metadata (pending a &lt;a href=&quot;https://github.com/rjournal/rjournal.github.io/pull/1&quot;&gt;pull request&lt;/a&gt;). Check out &lt;a href=&quot;https://github.com/cboettig/rjournal.github.io/commit/e70e84e6e53e6c04ec9864af162d7ba58439d4d5&quot;&gt;the source code&lt;/a&gt; for how this works – it’s really quite straight forward since the metadata is already available in &lt;code&gt;_config.yaml&lt;/code&gt;. The main step involves a &lt;a href=&quot;https://github.com/cboettig/rjournal.github.io/blob/e70e84e6e53e6c04ec9864af162d7ba58439d4d5/_plugins/article_html_pages.rb&quot;&gt;Generator plugin&lt;/a&gt; which builds a page for each article and makes the relevant article metadata available to the page. Then we can write a &lt;a href=&quot;https://github.com/cboettig/rjournal.github.io/blob/e70e84e6e53e6c04ec9864af162d7ba58439d4d5/_layouts/article.html&quot;&gt;page template&lt;/a&gt; using Liquid code to import the metadata.&lt;/p&gt;
&lt;p&gt;The really exciting thing about this is the basic idea of forking a journal website and improving it. There’s a lot we could do to improve the R journal. I think that ideally we’d have HTML5 versions of the articles as well, something that would be straight forward if authors used knitr of course, but I realize that’s a bigger shift. One could also automatically enhance the HTML with quite a bit more semantic content, we could have animations, links the Rnw files, etc etc. I’d be happy to help and I’m sure others would too. R-journal is great but it could be so much more as an example and test-bed of innovation in statistical publishing.&lt;/p&gt;
&lt;p&gt;Well, now that the journal is open for pull requests, hack away!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Reviewing Software Revisited</title>
	 <link href="/2013/07/09/reviewing-software-revisited.html"/>
   <updated>2013-07-09T00:00:00+00:00</updated>
   <id>/07/09/reviewing-software-revisited</id>
   <content type="html">&lt;p&gt;Several weeks ago I wrote a &lt;a href=&quot;/2013/06/13/what-I-look-for-in-software-papers.html&quot;&gt;post&lt;/a&gt; describing issues I commonly raise when reviewing software papers. This provoked a lively discussion among authors, editors, and other reviewers of software papers (most of us having been on at least both reviewing and authoring end), with quite varied perspectives as to whether such criteria were appropriate in this context. As I describe there, I view the concept of dedicated software papers as a somewhat necessary “hack” of the publishing system, and hope a more mature system will eventually come into place, as is now happening for data through efforts such as &lt;a href=&quot;http://datadryad.org&quot;&gt;Dryad&lt;/a&gt; and associated journal archiving requirements.&lt;/p&gt;
&lt;p&gt;Sustainability of the software is important for the same reason archiving the literature is important – without this, we cannot build on existing work. Building on “researcher/developer” software (e.g. the kind of software typically covered in ‘software papers’) is currently an uncommon and risky, as eloquently argued by Brian O’Meara in the comments of &lt;a href=&quot;http://carlboettiger.info/2013/04/23/we-need-more-object-oriented-design-in-comparative-methods.html&quot;&gt;an earlier post&lt;/a&gt; describing just such a failure.&lt;/p&gt;
&lt;p&gt;Through that discussion, I’ve come to see the goal of reviewing software papers as one of software sustainability. After all, the publication becomes a part of the researcher’s permanent record and part of the permanent scholarly archive, designed to outlive the journal itself. It seems reasonable that the software it describes should at least exist and do something five years later. Though this sentiment underlies most of my criteria, my phrasing is often too specific and a little too grounded in language explicit to software development.&lt;/p&gt;
&lt;p&gt;As I learned from Neil Chue Hong (&lt;a href=&quot;http://www.software.ac.uk/&quot;&gt;Software Sustainability Institute&lt;/a&gt;) in a follow up from that discussion, The Journal of Open Research Software has recently revised its guidelines making much of this more explicit and much better worded than I did. They provide separate lists for the reviewer to comment on both the paper and the software – making it clear that the review goes beyond the paper. The questions for the paper are every bit as valuable as those from the software section: for instance, reference to sections on “Reuse”, “Quality Control”, and “Implementation and Architecture”. While these things might not get their own section headings in an MEE paper, the ideas should certainly be addressed. I think these guidelines provide an excellent checklist for promoting sustainable software without putting undo emphasis on questions of performance, scalability, extensibility, etc.&lt;/p&gt;
&lt;h2 id=&quot;journal-of-open-research-softwares-guidelines&quot;&gt;Journal of Open Research Software’s Guidelines&lt;/h2&gt;
&lt;p&gt;(content below &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/&quot;&gt;CC-BY&lt;/a&gt;, quoted from &lt;a href=&quot;http://openresearchsoftware.metajnl.com/&quot;&gt;Journal of Open Research Software&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Please provide a list of your recommendations, indicating which are compulsory for acceptance and which are optional but would improve the quality of the paper or the reusability of the software.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;the-paper&quot;&gt;The paper&lt;/h3&gt;
&lt;ol type=&quot;a&quot;&gt;
&lt;li&gt;Is the title of the paper descriptive and objective?&lt;/li&gt;
&lt;li&gt;Does the Abstract give an indication of the software’s functionality, and where it would be used?&lt;/li&gt;
&lt;li&gt;Do the keywords enable a reader to search for the software?&lt;/li&gt;
&lt;li&gt;Does the Introduction give enough background information to understand the context of the software’s development and use?&lt;/li&gt;
&lt;li&gt;Does the Implementation and Architecture section give enough information to get an idea of how the software is designed, and any constraints that may be placed on its use?&lt;/li&gt;
&lt;li&gt;Does the Quality Control section adequately explain how the software results can be trusted?&lt;/li&gt;
&lt;li&gt;Does the Reuse section provide concrete and useful suggestions for reuse of the software, for instance: other potential applications, ways of extending or modifying the software, integration with other software?&lt;/li&gt;
&lt;li&gt;Are figures and diagrams used to enhance the description? Are they clear and meaningful?&lt;/li&gt;
&lt;li&gt;Do you believe that another researcher could take the software and use it, or take the software and build on it?&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;the-software&quot;&gt;The software&lt;/h3&gt;
&lt;ol type=&quot;a&quot;&gt;
&lt;li&gt;Is the software in a suitable repository? (see &lt;a href=&quot;http://openresearchsoftware.metajnl.com/about/repositories/&quot; class=&quot;uri&quot;&gt;http://openresearchsoftware.metajnl.com/about/repositories/&lt;/a&gt; for more information)&lt;/li&gt;
&lt;li&gt;Does the software have a suitable open licence? (see &lt;a href=&quot;http://openresearchsoftware.metajnl.com/faq/#q5&quot; class=&quot;uri&quot;&gt;http://openresearchsoftware.metajnl.com/faq/#q5&lt;/a&gt; for more information)&lt;/li&gt;
&lt;li&gt;If the Archive section is filled out, is the link in the form of a persistent identifier, e.g. a DOI? Can you download the software from this link?&lt;/li&gt;
&lt;li&gt;If the Code repository section is filled out, does the identifier link to the appropriate place to download the source code? Can you download the source code from this link?&lt;/li&gt;
&lt;li&gt;Is the software license included in the software in the repository? Is it included in the source code?&lt;/li&gt;
&lt;li&gt;Is sample input and output data provided with the software?&lt;/li&gt;
&lt;li&gt;Is the code adequately documented? Can a reader understand how to build/deploy/install/run the software, and identify whether the software is operating as expected?&lt;/li&gt;
&lt;li&gt;Does the software run on the systems specified? (if you do not have access to a system with the prerequisite requirements, let us know)&lt;/li&gt;
&lt;li&gt;Is it obvious what the support mechanisms for the software are?&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;p&gt;Like my own list, a repository, a license, and sample input-output data are all mentioned explicitly. Software review section suggests there should be a mechanism in place to “identify whether the software is operating as expected” – such as basic unit tests. Extensibility is also mentioned, but without any reference to features that may or may not assist in that – a fault of my own list, which was probably over-specific on that account. I think these are reasonable and solid guidelines, and would love to see other journals that frequently publish software papers (Looking at you, MEE, JSS, Bioinformatics, R Journal, PLoS Comp Bio) adopt similar criteria.&lt;/p&gt;
&lt;p&gt;Of course I’d love to hear what others think about this.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What I look for in 'Software Papers'</title>
	 <link href="/2013/06/13/what-I-look-for-in-software-papers.html"/>
   <updated>2013-06-13T00:00:00+00:00</updated>
   <id>/06/13/what-I-look-for-in-software-papers</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt; Thanks to the rich discussion in the comments and beyond, I’ve revised my thoughts on this somewhat, as I discuss in &lt;a href=&quot;/2013/07/09/reviewing-software-revisited.html&quot;&gt;this more recent post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I am more and more frequently reviewing ‘software papers:’ which I define as publications whose primary purpose is to publicize a piece of scientific software and provide a traditional research product with hopes that it will receive citations and recognition from other researchers in grant and job reviews. To me this feels very much like hacking the publication recognition system rather than the ideal way to recognize and track the role of software in research communities, but a very practical one in the current climate. I have written two myself, so I have been on both ends of this issue. In this post, I share what I look for in such papers and what omissions I see most frequently.&lt;/p&gt;
&lt;h2 id=&quot;reviewing-software&quot;&gt;Reviewing software&lt;/h2&gt;
&lt;p&gt;If we are going to employ this hack of the publication system for software, we should at least use it to maximal advantage. As a reviewer, I feel that means reviewing not just the submitted manuscript but the software itself. If we can agree on nothing else, we as a community should at least be able to say:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;my review of a software paper is a review of the software&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I assume most other authors, reviewers and editors on this content share this implicit assumption, but I’d love to hear first hand from anyone else. For instance: as an editor, what would you do if your reviewers only commented on the paper directly and not on the software distributed?&lt;/p&gt;
&lt;p&gt;We are not really taught to review software, any more than we are taught to write it in the first place. Most journals offer little guidance on this (though see the Journal of Open Research Software &lt;a href=&quot;http://openresearchsoftware.metajnl.com/peer-review/&quot;&gt;guidelines for peer review of software&lt;/a&gt;, all though they are still rather minimal.) In the absence of a culture on software reviewing, I thought I would lay out my own perspective with the hope of hearing feedback and push back from others. Perhaps through such dialogs we can develop clearer expectations for this rapidly expanding genre.&lt;/p&gt;
&lt;h2 id=&quot;reviewing-the-software-paper&quot;&gt;Reviewing the software paper&lt;/h2&gt;
&lt;p&gt;I don’t include “to document” the software as a purpose, since none do so very comprehensively, and besides, documentation belongs in the software, not in a journal. “Publicize” usually includes some motivating examples that could convince many readers that the software does something useful for them without too much effort. As such, I expect the paper to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;provide the journal’s audience with a clear motivation for why the package is useful, * and have at least one functioning “wow” example that I can run (by copy-paste) and understand without difficulty (e.g. without referring to code comments or the package manual to understand the function calls and their arguments).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is an intentionally low bar that I hope helps promote these kinds of contributions. Despite this, papers frequently fail the copy-paste test or the plain text explanations of the function calls. Come on people. Meanwhile, I try to focus the rest of my review on the software itself.&lt;/p&gt;
&lt;h2 id=&quot;my-partial-list-of-criteria&quot;&gt;My partial list of criteria&lt;/h2&gt;
&lt;p&gt;As I am almost always reviewing R packages, the software already meets some very basic standards required by submission to CRAN: dependencies and license stated, built-in documentation, passing some minimal automatic checks, etc. (See the &lt;a href=&quot;http://cran.r-project.org/web/packages/policies.html&quot;&gt;CRAN Policies&lt;/a&gt; and the &lt;a href=&quot;http://cran.r-project.org/doc/manuals/R-exts.html&quot;&gt;Writing R Extensions Manual&lt;/a&gt; for details). This is great, as it clears the first few hurdles of installation, etc. without much fuss, but still provides a bar that is by itself unacceptably low for published scientific software. Here is a list of the things I see that most often frustrate me. This isn’t intended as a style-guide or a comprehensive list of best practices, just my own pet peeves. I have somewhat tongue-in-cheek labeled them by severity of the review I might give; which like any other use of these terms is more of a measure of how annoyed I am then anything else. Critiques and suggestions welcome.&lt;/p&gt;
&lt;h3 id=&quot;edit&quot;&gt;Edit:&lt;/h3&gt;
&lt;p&gt;The comments from other reviewers, authors, and editors have been fantastic, thank you all. I particularly appreciate the opportunity to have reviewing styles critiqued, something that does not happen in normal peer review.&lt;/p&gt;
&lt;p&gt;Just a note on my headings here. I do not see any of these things as “gatekeeping requirements” and have intentionally omitted the option of “&lt;em&gt;Reject&lt;/em&gt;”. I would reject such a paper for methodological flaws, etc., but not for any of the reasons on my list below. The list is intended only to improve, not prevent, software publication.&lt;/p&gt;
&lt;p&gt;I believe any of the decisions below typically result in a revision to the same journal, that authors judiciously choose how to respond to reviewer comments guided by the editor’s own feedback, and that it is ultimately the editor’s decision whether any of this is relevant. &lt;code&gt;&amp;lt;/edit&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;reject-and-resubmit&quot;&gt;“Reject and resubmit”&lt;/h2&gt;
&lt;h3 id=&quot;automatic-tests&quot;&gt;Automatic tests&lt;/h3&gt;
&lt;p&gt;A scientific R package &lt;em&gt;must must must&lt;/em&gt; have some automated tests that are run by &lt;code&gt;R CMD check&lt;/code&gt;. Even if further development of the package doesn’t break anything (most likely only if further development doesn’t happen), changes to the package dependencies could still break things, and so it is crucial to have a mechanism in place to detect these problems when they arise. For code that runs quickly, the simplest way to do this is through the examples in the documentation. I don’t expect all scientific software to have a complete test suite with 100% coverage covering all the weird things that can happen if a user passes in a matrix when the function expects a data frame or has some unanticipated missing values, etc. Just some tests to make sure the basic examples execute and I’ll be happy. Longer running functions or those that need calls to external web resources shouldn’t be run in the examples (too much of a burden for CRAN’s automatic testing) so they should be marked &lt;code&gt;dontrun&lt;/code&gt; and put in a separate test suite or vignette as it says in the manual.&lt;/p&gt;
&lt;h3 id=&quot;passing-optional-arguments&quot;&gt;Passing optional arguments&lt;/h3&gt;
&lt;p&gt;I see authors write functions like this all the time:&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;f &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;myfunction&lt;/span&gt;(f, p){ 
  &lt;span class=&quot;co&quot;&gt;#  stuff&lt;/span&gt;
  o &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;optim&lt;/span&gt;(f, p)
  &lt;span class=&quot;co&quot;&gt;#  stuff&lt;/span&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;calling an existing library function like &lt;code&gt;optim&lt;/code&gt; that has a whole host of very useful optional arguments that have a significant impact on how the algorithm functions. Whenever you a rich function like &lt;code&gt;optim&lt;/code&gt;, please have the courtesy to make it’s arguments available to future users and developers through your function call. Yes, most users will just want the default arguments, (or your default arguments, if different), and that can be handled just fine by providing default values as optional arguments. R has a fantastic mechanism for this exact issue: the &lt;code&gt;...&lt;/code&gt; argument. The above code could be fixed simply by using:&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;f &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;myfunction&lt;/span&gt;(f, p, ...){ 
  &lt;span class=&quot;co&quot;&gt;#  stuff&lt;/span&gt;
  o &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;optim&lt;/span&gt;(f, p, ...)
  &lt;span class=&quot;co&quot;&gt;#  stuff&lt;/span&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which works just they way you think it would. If you have more than one such function (ask yourself if you can write shorter functions first and then) pass optional arguments as lists,&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;f &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;myfunction&lt;/span&gt;(f, p, optim_options, fn2_options){
  &lt;span class=&quot;co&quot;&gt;# stuff&lt;/span&gt;
  o &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;do.call&lt;/span&gt;(optim, &lt;span class=&quot;kw&quot;&gt;as.list&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(f, p, optim_options)))
  &lt;span class=&quot;co&quot;&gt;# stuff&lt;/span&gt;
  b &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;do.call&lt;/span&gt;(fn2, fn2_options)
  &lt;span class=&quot;co&quot;&gt;# stuff &lt;/span&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;arguments can also be extracted with &lt;code&gt;list(...)$arg1&lt;/code&gt; etc.&lt;/p&gt;
&lt;p&gt;A converse of this issue is not providing default arguments where it might be natural to do so. This does not bother me so much, as it is probably useful to force the user to think how many iterations &lt;code&gt;n&lt;/code&gt; are appropriate for their problem rather than just assuming that &lt;code&gt;100&lt;/code&gt; is good because it is the default. The only time this case is annoying is when the argument will not be changing – such as a user’s authentication token to access a web resource. Don’t make me manually pass the token to every function in the library please.&lt;/p&gt;
&lt;h3 id=&quot;development-site-and-bug-tracker&quot;&gt;Development site and bug tracker&lt;/h3&gt;
&lt;p&gt;I would really like to see a link to the software development page, such as r-forge or Github. The primary asset in this context is pointing reviewers to an address with a bug tracking system where issues can be assigned ticket numbers and readers can transparently see if a package is being actively maintained. A reader who comes across the paper years later who has only an email address that may or may not work has little way to determine what the latest version of the code is, whether it is actively maintained, or whether earlier versions that may have been in used in previous publications suffered from any significant bugs.&lt;/p&gt;
&lt;h3 id=&quot;cite-your-dependencies&quot;&gt;Cite your dependencies!&lt;/h3&gt;
&lt;p&gt;We write software papers with the sometimes vain hope that they will be cited by users, so authors of such papers should at least follow these best practices themselves. R includes a native mechanism for providing citations to packages, &lt;code&gt;citation(packagename)&lt;/code&gt;, including the information for any software paper published along with it. Be sure to add your own software papers to the &lt;code&gt;CITATION&lt;/code&gt; file. More information can be found in my post on &lt;a href=&quot;http://purl.org/cboettig/2012/03/20/citing-r-packages.html&quot;&gt;Citing R packages&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;major-revisions&quot;&gt;“Major Revisions”&lt;/h2&gt;
&lt;p&gt;These are other things that commonly frustrate me, but fall on a bit more of a continuum of style rather than gross oversights. As such I’m not sure that any one of these things would justify rejection.&lt;/p&gt;
&lt;h3 id=&quot;functionalize-the-code&quot;&gt;Functionalize the code&lt;/h3&gt;
&lt;p&gt;Style guides will tell you to keep functions short, not more than a screen or 20 lines. Breaking large functions into a series of smaller functions and documenting those smaller functions – even if they are only used internally – is a great help to a reviewer trying to understand what a function is supposed to do and also test that it does what it says. Anyone building the code base later (most often yourself) will appreciate the reusable modules.&lt;/p&gt;
&lt;h3 id=&quot;stable-clean-and-complete-return-objects&quot;&gt;Stable, clean, and complete return objects&lt;/h3&gt;
&lt;p&gt;An extension of providing optional arguments to functions is to also provide access to all of their return information. To extend the example from wrapping &lt;code&gt;optim&lt;/code&gt;, this would involve returning the convergence information. Using object classes and helper functions for return objects helps keep code stable and lets users leverage existing code for similar objects, such as fitting or plotting routines. More discussion on this topic based on my own experiences in the post, &lt;a href=&quot;http://carlboettiger.info/2013/04/23/we-need-more-object-oriented-design-in-comparative-methods.html#comment-878249659&quot;&gt;we need more object oriented design in comparative methods&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;state-a-license&quot;&gt;State a license&lt;/h3&gt;
&lt;p&gt;Because CRAN requires this through the DESCRIPTION file, R package authors rarely neglect this entirely. A sometimes misconception is that because R itself is primarily dual-licensed under GPL-2 and GPL-3 that R packages must use a GPL license due to the “viral” clause of the GPL. This clause only applies if you are modifying existing GPL functions directly and is not a requirement for R packages, which recognize a large array of licenses. My own recommendation for authors seeking to maximize the impact of their work is to use MIT, BSD (2 clause), or CC0 license for the package. CC0 has the advantage of being suitable for and data or documentation included, but authors should do there homework and decide what is best for them.&lt;/p&gt;
&lt;h2 id=&quot;minor-revisions&quot;&gt;“Minor Revisions”&lt;/h2&gt;
&lt;p&gt;Consistent use of coding style, good documentation, clear examples, intelligent reuse of code, and other best practices are all areas in which any work could improve. While we can all become better developers by highlighting these issues in our reviews, they are probably best developed over time and in dialog with the user community. I also put anything extending the scope of functionality into this category – I do not have any concept of minimal contribution as long as the code meets the criteria above. Meanwhile, there’s always a few pet peeves I just cannot help mentioning. Here’s one which is particular to R packages and so commonly overlooked.&lt;/p&gt;
&lt;h3 id=&quot;imports-not-depends&quot;&gt;IMPORTS not DEPENDS&lt;/h3&gt;
&lt;p&gt;Many developers overlook that package dependencies that provide functions your functions will use internally should be listed as under IMPORTS rather than DEPENDS. This keeps the users namespace cleaner and avoids collisions of functions having the same name. Use DEPENDS only for those packages whose functions will be used by the end user as well.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;If you are an author, editor, or reviewer of R software packages, what are your pet peeves?&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>manuscript reviews on github?</title>
	 <link href="/2013/06/10/mansucript-reviews-on-github.html"/>
   <updated>2013-06-10T00:00:00+00:00</updated>
   <id>/06/10/mansucript-reviews-on-github</id>
   <content type="html">&lt;p&gt;I was recently impressed to learn of Trevor Bedford’s strategy of seeking &lt;a href=&quot;https://twitter.com/trvrb/status/334310856982671361&quot;&gt;pre-approval&lt;/a&gt; for posting his reviewer’s comments as Github issues. Beyond providing links to the data and source-code, I generally don’t advertise the open science nature of papers I submit – I guess I assume that if the reader or reviewers care, it should be easy enough for them to discover it. Consequently I am usually immediately frustrated to realize that upon receiving my reviews I have to create a second, private repository for the review material, our replies to reviewers, etc., as I don’t have permission to disclose that information. &lt;a href=&quot;#fn1&quot; class=&quot;footnoteRef&quot; id=&quot;fnref1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; I have recently stumbled across &lt;a href=&quot;http://www.steinsaltz.me.uk/pnas.html&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;http://theseamonster.net/2013/05/are-unreasonably-harsh-reviewers-retarding-the-pace-of-coral-reef-science/&quot;&gt;examples&lt;/a&gt; of authors publishing to the web anonymous reviews they have received. Though anonymous, I feel the practice potentially murky without explicit permission, so I would appreciate any insight others have on this.&lt;/p&gt;
&lt;h3 id=&quot;asking-permission&quot;&gt;Asking permission&lt;/h3&gt;
&lt;p&gt;Trevor’s approach suggests I should consider broaching this question when first submitting my review, so I am puzzling over the best way to do so. One option would be to include such a request in the cover letter. For example,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The authors of this manuscript would like to request that the editor and reviewers indicate in their replies if they consent or decline to have their comments posted anonymously in the public &lt;a href=&quot;#&quot;&gt;Issues Tracker&lt;/a&gt; of this paper.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Does that need more explanation? A link to examples like &lt;a href=&quot;https://github.com/trvrb/flux/issues?labels=reviewer+1&quot;&gt;Trevor’s&lt;/a&gt; that have done this before? Do I need to explain the value of having this kind of transparent provenance for the paper? Should I mention how this could give the reviewer more transparent credit? Encourage them to comment directly on Github from their own account?&lt;/p&gt;
&lt;p&gt;Does this need the blessing of the journal? How would you feel about such a clause as a reviewer or editor? For a recent review I had done of a paper that was similarly written on Github, I obtained the Journal’s permission to post my review as an &lt;a href=&quot;https://github.com/weecology/data-sharing-paper/issues/71&quot;&gt;issue&lt;/a&gt; in their repository. I would love to see more examples of this kind of thing, if anyone has come across them.&lt;/p&gt;
&lt;h2 id=&quot;cover-letters-for-open-science-manuscripts&quot;&gt;Cover letters for open science manuscripts?&lt;/h2&gt;
&lt;p&gt;While I lean towards a minimal statement such as the one above, perhaps a cover letter would be a good place to document some of the other open and reproducible features of the manuscript? Or perhaps such statements should be added to the manuscript itself? Among the options, I might point out:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;The manuscript has been written on Github. Consequently the full drafting and &lt;strong&gt;revision history&lt;/strong&gt; is available, along with graphs of author contributions (which omit authors without Github accounts and may be distorted by trivial line changes)&lt;/li&gt;
&lt;li&gt;The manuscript has been written with all the code necessary to repoduce the results embedded as a &lt;a href=&quot;http://yihui.name/knitr&quot;&gt;knitr&lt;/a&gt; &lt;strong&gt;dynamic document&lt;/strong&gt;. This helps ensure the analysis is always in synch with the results presented in the manuscript and the that the research is reproducible. The analysis, figures, and manuscript can be reassembled from scratch by typing &lt;code&gt;make pdf&lt;/code&gt; in the repository directory.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Code&lt;/strong&gt; to replicate the analysis and produce each of the figures shown can be found at: (Version-stable lnk to the appropriate Github pages? Deposit in Figshare/Dryad first?)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data&lt;/strong&gt; to replicate the analysis and data shown in each of the figures can be found at: (Easiest to link to Github, since the code and data already reside there.&lt;br /&gt;&lt;em&gt;Alternatively I could deposit these in &lt;a href=&quot;http://figshare.com&quot;&gt;Figshare&lt;/a&gt; or &lt;a href=&quot;http://datadryad.org&quot;&gt;Dryad&lt;/a&gt; first…)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;The manuscript, code, data, and documentation are available &lt;strong&gt;as an R package in the Github repository&lt;/strong&gt;.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;issues tracker&lt;/strong&gt; associated with the manuscript’s repository provides a record of this research, including lines of investigation that were resolved into the results presented here, lines that were closed as dead-ends or null results, and outstanding issues for further investigation.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;daily lab notebook entries&lt;/strong&gt; accompanying this research can be found under the &lt;a href=&quot;/tags&quot;&gt;project-tag&lt;/a&gt; between dates of XX and XX.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Listing all of these would make for a somewhat lengthy cover letter, which might be a bit overwhelming to be useful (or seem more promotional than valuable). Are any of the seven things above worth highlighting in particular?&lt;/p&gt;
&lt;p&gt;Perhaps these details could be deferred to a README file in the project’s Github repo, and the cover letter could simply provide a link to the project repository? What, if anything, would appear most useful and accessible to a reviewer unfamiliar with this approach or its potential value? Though elements of this approach have been discussed in the published literature, e.g. &lt;span class=&quot;showtooltip&quot; title=&quot;Gentleman R and Temple Lang D (2007). Statistical Analyses And
Reproducible Research. _Journal of Computational And Graphical
Statistics_, *16*. ISSN 1061-8600, 
http://dx.doi.org/10.1198/106186007X178663.&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1198/106186007X178663&quot; rel=&quot;http://purl.org/spar/cito/citesAsEvidence&quot; &gt;Gentleman &amp;amp; Temple Lang (2007)&lt;/a&gt;&lt;/span&gt; ‘compendium’ concept, &lt;span class=&quot;showtooltip&quot; title=&quot;Stodden V (2009). Enabling Reproducible Research: Open Licensing
for Scientific Innovation. 
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040. 
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040.&quot;&gt;&lt;a href=&quot;http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040&quot; rel=&quot;http://purl.org/spar/cito/citesAsEvidence&quot; &gt;Stodden (2009)&lt;/a&gt;&lt;/span&gt; RRS concept, or &lt;span class=&quot;showtooltip&quot; title=&quot;Peng R (2011). Reproducible Research in Computational Science.
_Science_, *334*. ISSN 0036-8075, 
http://dx.doi.org/10.1126/science.1213847.&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1126/science.1213847&quot; rel=&quot;http://purl.org/spar/cito/citesAsEvidence&quot; &gt;Peng (2011)&lt;/a&gt;&lt;/span&gt; reproducible papers in the Journal of Biostatistics, I’m unsure if pointing a reviewer to these references would be more valuable or more confusing. Let me know what you think.&lt;/p&gt;
&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Robert Gentleman, Duncan Temple Lang, (2007) Statistical Analyses And Reproducible Research. &lt;em&gt;Journal of Computational And Graphical Statistics&lt;/em&gt; &lt;strong&gt;16&lt;/strong&gt; &lt;a href=&quot;http://dx.doi.org/10.1198/106186007X178663&quot;&gt;10.1198/106186007X178663&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R. D. Peng, (2011) Reproducible Research in Computational Science. &lt;em&gt;Science&lt;/em&gt; &lt;strong&gt;334&lt;/strong&gt; &lt;a href=&quot;http://dx.doi.org/10.1126/science.1213847&quot;&gt;10.1126/science.1213847&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Victoria Stodden, (2009) Enabling Reproducible Research: Open Licensing for Scientific Innovation. &lt;a href=&quot;http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040&quot; class=&quot;uri&quot;&gt;http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1362040&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&quot;footnotes&quot;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&quot;fn1&quot;&gt;&lt;p&gt;Strictly speaking the edits to the manuscript in the open repository could also be considered confidential, though at that stage I haven’t yet signed the copyright agreements that come with publication, which tend to be quite reasonable even for the traditional subscription based journals I work with&lt;a href=&quot;#fnref1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
 </entry>
 
 <entry>
   <title>DOI != citable</title>
	 <link href="/2013/06/03/DOI-citable.html"/>
   <updated>2013-06-03T00:00:00+00:00</updated>
   <id>/06/03/DOI-citable</id>
   <content type="html">&lt;p&gt;I feel I see this kind of comment almost daily:&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-partner=&quot;tweetdeck&quot;&gt;
&lt;p&gt;
Is there a way to obtain DOI for a &lt;a href=&quot;https://twitter.com/github&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;github&quot;&gt;@github&lt;/span&gt;&lt;/a&gt; repository? (for citing &lt;a href=&quot;https://twitter.com/search?q=%23opensource&amp;amp;src=hash&quot;&gt;#opensource&lt;/a&gt; software packages, similar to &lt;a href=&quot;https://twitter.com/figshare&quot;&gt;&lt;span class=&quot;citation&quot; data-cites=&quot;figshare&quot;&gt;@figshare&lt;/span&gt;&lt;/a&gt; objects) &lt;a href=&quot;https://twitter.com/search?q=%23git&amp;amp;src=hash&quot;&gt;#git&lt;/a&gt;
&lt;/p&gt;
— Ahmed Moustafa (&lt;span class=&quot;citation&quot; data-cites=&quot;AhmedMoustafa&quot;&gt;@AhmedMoustafa&lt;/span&gt;) &lt;a href=&quot;https://twitter.com/AhmedMoustafa/statuses/339727912896954369&quot;&gt;May 29, 2013&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;Again and again, researchers suggest that DOI to makes something “citable”. And this &lt;a href=&quot;https://twitter.com/cboettig/status/337986074624282624&quot;&gt;frustrates me&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Don’t get me wrong. I love DOIs, and I love CrossRef. And I bang on the table when I have some old journal article that doesn’t yet have a DOI. I use DOIs every day in many ways. I use CrossRef’s APIs all the time to draw in metadata for citations in my notebook (through my &lt;a href=&quot;http://github.com/cboettig/knitcitations&quot;&gt;knitcitations&lt;/a&gt; package), and to import metadata into my reference manager, Mendeley. I’ve written my own implementations in R and ruby, and keep an eye on their exciting new tools on the &lt;a href=&quot;https://github.com/crossref&quot;&gt;Crossref Github page&lt;/a&gt;. I wrote to bibsonomy when I realized they were not using the CrossRef API to look up metadata by DOIs, and they have now implemented this feature. I use DOIs to look up papers I’ve come across, and to share content I am reading. (Crossref’s &lt;a href=&quot;http://shortdoi.org/&quot;&gt;DOI shortener&lt;/a&gt; is great for this). I even use DOI-based links to &lt;a href=&quot;http://carlboettiger.info/2013/02/22/semantic-citations-for-the-notebook-and-knitr.html&quot;&gt;embed semantic information&lt;/a&gt; into links and citations of articles.&lt;/p&gt;
&lt;p&gt;But I still have no idea what researchers mean when they suggest that this makes something &lt;em&gt;citable&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&quot;some-background-on-dois&quot;&gt;Some background on DOIs&lt;/h3&gt;
&lt;p&gt;At its heart, a DOI is a very simple concept. It is a “permanent identifier”. All this means is that is is really just a URL redirect. Type http://dx.doi.org/mnn into any browser and get redirected to where the article actually lives. Why does that make it permanent? Because if the journal decides to change their URL structure, the DOI’s redirect can just be mapped to the new address and voila, it still works. That is, a DOI is simply a tool to fight &lt;a href=&quot;https://en.wikipedia.org/wiki/Link_rot&quot;&gt;link-rot&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So you might ask, why does the ability to remap the address have anything to do with being “permanent?” It doesn’t, really. The permanence comes not so much from the technology as from the social contract that goes with it. As CrossRef’s &lt;a href=&quot;http://blogs.plos.org/mfenner/2009/02/17/interview_with_geoffrey_bilder/&quot;&gt;Geoffery Bilder eloquently explains&lt;/a&gt;, a publisher can only receive DOIs if they promise to keep these redirects up-to-date. A publisher who fails to maintain this responsibility would presumably lose their right to receive DOIs. A brilliant, simple, social incentive.&lt;/p&gt;
&lt;p&gt;This still does not guarantee permanence – e.g. what would happen to the content if the publisher disappears. That problem is not addressed by the DOI technology itself, but by a robust backup archiving solution, such as &lt;a href=&quot;http://clockss.org&quot;&gt;CLOCKSS&lt;/a&gt;, which provides a geo-politically distributed network of backup copies for many journals. Again the social contract comes into play – presumably CrossRef would not provide a publisher with DOIs if they did not have such a robust archival solution in place.&lt;/p&gt;
&lt;p&gt;So far we have seen two crucial functions of the DOI – as a permanent identifier that can be used to reach the content despite link rot, and as an incentive to maintain good archival backups of the content and the links to it.&lt;/p&gt;
&lt;h3 id=&quot;what-do-we-mean-by-citations-anyway&quot;&gt;What do we mean by citations, anyway?&lt;/h3&gt;
&lt;p&gt;So what does this have to do with being citable? Obviously these are nice properties to have for things we cite – but they are by no means a requirement. (As &lt;a href=&quot;https://twitter.com/noamross/status/337987521243918337&quot;&gt;Noam Ross observes&lt;/a&gt;, try finding a permanent identifier for “Personal Communication”). Books, reports, and other grey literature frequently appear in citations, as do links to websites. MLA even has guidelines on the proper format to &lt;a href=&quot;http://www.mla.org/style/handbook_faq/cite_a_tweet&quot;&gt;cite a tweet&lt;/a&gt; (which, incidentally, come closer to having a permanent identifier and an archival strategy than most other things in this list). So what do we mean by citable anyway?&lt;/p&gt;
&lt;p&gt;But what about the reference list? While a publisher may be just fine including some link to your software, is it really cited if it isn’t in the reference list? Journals restrict what appears in the reference list because these references are indexed by the infamous citation counters like Thompson-Reuters. (A frequent complaint is that many journals do not similarly index citations appearing in the reference list of the supplementary materials, making it difficult or impossible to give appropriate attribution to large numbers of data providers, for instance). Does having a DOI address this problem?&lt;/p&gt;
&lt;h4 id=&quot;citation-counts-in-dois&quot;&gt;Citation counts in DOIs&lt;/h4&gt;
&lt;p&gt;Counting citations depends on who is counting them. The most well-known is Thompson-Reuters, which has their own process for deciding what gets counted (based on publisher), so no guarantee there. Meanwhile Google Scholar counts anything meeting it’s &lt;a href=&quot;http://carlboettiger.info/2012/11/23/citing-lab-notebook-entries.html&quot;&gt;indexing requirements &amp;amp; arbitrary selection&lt;/a&gt;. I have recently learned that CrossRef just launched it’s own &lt;a href=&quot;https://github.com/articlemetrics/alm/wiki/Crossref&quot;&gt;internal citation counting&lt;/a&gt;, which is available from the CrossRef metadata (totals only for the public, publishers can resolve which articles did the citing…). However, most proposals to make some alternative research product “citable” by giving it a DOI use DataCite DOIs (e.g. fig&lt;strong&gt;share&lt;/strong&gt;, PeerJ Preprints), which lag behind in this feature. Moving the control of citation data beyond the grasp of particular publishing companies like TR is undoubtedly an important step forward. The &lt;a href=&quot;http://www.jisc.ac.uk/whatwedo/programmes/inf11/jiscexpo/jiscopencitation.aspx&quot;&gt;Open Citation Project&lt;/a&gt; is a more comprehensive, if very young, move in this direct. (Hat tip to Martin Fenner for explaining CrossRef citations to me).&lt;/p&gt;
&lt;h3 id=&quot;additional-metadata&quot;&gt;Additional Metadata&lt;/h3&gt;
&lt;p&gt;In addition to resolving links, DOI providers also serve a rich collection of metadata about the publication that can be &lt;a href=&quot;http://www.crosscite.org/cn/&quot;&gt;queried by DOI&lt;/a&gt; or by &lt;a href=&quot;https://github.com/CrossRef/cr-search&quot;&gt;other elements&lt;/a&gt; like author and title. Rich semantic formats and disambiguation of author names by connections to ORCID IDs are among the many advantages of this. Because many of these tools are publicly accessible by through their APIs, it is easy for other developers to build services upon them.&lt;/p&gt;
&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;While DOI providers have done an excellent job in ensuring persistent URLs, archived content, and valuable metadata, these things are largely the product of the social contract between publisher and the DOI provider. It is not possible for an author or organization to simply “get DOIs” for all their content. But it is not the only way to provide these features, either. While I understand the value in providing a simple and reliable way to encapsulate each of these concepts as “has a DOI,” it also appears to put these features beyond the reach of individual researchers. If issues of persistent URLs, archived content, and rich metadata tools are always reduced to “has a DOI,” publishers become the only path to achieve these ends. On the contrary, a rich collection of tools is available to researchers.&lt;/p&gt;
&lt;p&gt;So what do we mean when we say a DOI makes something ‘citable?’ If this is shorthand for the properties we would want in something citable: persistent identifier, archival content, machine-readable metadata, than we should start to recognize other things that share these features. Further innovation requires valuing the features the DOI provides, not simply a “brand name” researchers recognize.&lt;/p&gt;
&lt;h2 id=&quot;alternative-tools&quot;&gt;Alternative tools&lt;/h2&gt;
&lt;p&gt;In a &lt;a href=&quot;http://purl.org/cboettig/2013/05/31/notebook-features-digital-archiving&quot;&gt;recent post&lt;/a&gt; in a series on technical features of my open notebook, I discuss some of the tools available to address these challenges. In particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The use of &lt;a href=&quot;http://en.wikipedia.org/wiki/Persistent_uniform_resource_locator&quot;&gt;PURLs&lt;/a&gt; for persistent identifiers&lt;/li&gt;
&lt;li&gt;Git for archival redundancy&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://greycite.knowledgeblog.org&quot;&gt;Greycite&lt;/a&gt; for metadata extraction&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course, if you ever need a DOI for a research product, there is always &lt;a href=&quot;http://figshare.com&quot;&gt;figshare&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Notebook features: digital archiving</title>
	 <link href="/2013/05/31/notebook-features-digital-archiving.html"/>
   <updated>2013-05-31T00:00:00+00:00</updated>
   <id>/05/31/notebook-features-digital-archiving</id>
   <content type="html">&lt;p&gt;Note: this entry is part of a &lt;a href=&quot;http://carlboettiger.info/2013/04/26/notebook-features-introduction.html&quot;&gt;series of posts&lt;/a&gt; which explain some of the technical features of my lab notebook.&lt;/p&gt;
&lt;p&gt;Archival preservation of digital scholarly content is an important challenge throughout the research community. As the notebook is the permanent record of my regular scholarly endeavors, this provides the opportunity to experiment with tools and techniques for digital archiving while also better preserving the notebook. In the experimental spirit that drives all my exploration here, I am testing several ways to accomplish this. In so doing, I learn which approaches are easiest to implement, to use, and gather feedback from, while also hedging my bets in the event that any given strategy should fail.&lt;/p&gt;
&lt;p&gt;Archiving digital content involves two fundamental challenges that can be difficult to satisfy simultaneously: providing a robust backup copy of the &lt;em&gt;content&lt;/em&gt;, and providing a consistent location (such as a URL) where the content can be retrieved.&lt;/p&gt;
&lt;h2 id=&quot;a-custom-domain&quot;&gt;A custom domain&lt;/h2&gt;
&lt;p&gt;The simplest archival measure employed in the notebook comes from hosting through my own domain, &lt;a href=&quot;http://carlboettiger.info&quot;&gt;carlboettiger.info&lt;/a&gt; rather than an external server. By controlling the domain structure myself, I am not tied to a University server that can be altered by an IT department without my knowledge, thereby breaking my links. When I choose to move platforms, as I did in migrating from &lt;a href=&quot;/2012/09/19/migrating-from-wordpress-to-jekyll.html&quot;&gt;Wordpress to Jekyll&lt;/a&gt;, I could ensure that links would be appropriately mapped. This was not the case when I started my open notebook on the OpenWetWare platform, since links are all mapped to the &lt;a href=&quot;http://openwetware.org&quot;&gt;openwetware.org&lt;/a&gt; domain which I obviously cannot control, even though I could at least migrate my content. &lt;a href=&quot;https://github.com/cboettig/labnotebook/blob/8481569132142c850e585a2fc8c12a671527cd4f/_plugins/redirects.rb&quot;&gt;HTML redirects&lt;/a&gt; make sure links still resolve when I change structure (e.g. &lt;a href=&quot;/archives/211&quot;&gt;carlboettiger.info/archives/211&lt;/a&gt;). I don’t have to worry about moving my domain when I change institutions, and can seamlessly migrate to a different server or DNS provider to get better rates or uptime performance.&lt;/p&gt;
&lt;p&gt;Of course these advantages are also the greatest weaknesses of this approach – they all depend entirely on me. I could make or forget to make any number of changes that could cause this all to break. Time has shown that even the best-intentioned researchers are not the best curators of there own data, and no doubt I am no exception. How can the content and its identifying addresses outlive me or my interest in it?&lt;/p&gt;
&lt;h2 id=&quot;purls-preserving-identifiers&quot;&gt;PURLs: preserving identifiers&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://purl.org&quot;&gt;PURLs&lt;/a&gt;, or Persistent Uniform Resource Locators, provide a DOI-like mechanism for addressing the challenge of link-rot. As &lt;a href=&quot;http://blogs.plos.org/mfenner/2009/02/17/interview_with_geoffrey_bilder/&quot;&gt;Geoffrey Bilder eloquently argues&lt;/a&gt;, the technological solution is quite simple, the real challenge lies on the social side of the implementation – a social contract that promises content providers will maintain their identifiers if they want to continue to receive identifiers. Though users must register to be able to create PURLs, PURL does not provide such enforcement.&lt;/p&gt;
&lt;p&gt;The PURLs solution is a bit more web-native solution than DOIs, in being more democratic, using a URL structure, and being built upon widely distributed servers and open-source web technology. Not surprisingly, other web-native systems such as most of the major semantic web ontology providers rely on PURLs, e.g. Dublin Core uses &lt;a href=&quot;http://purl.org/dc/terms/&quot;&gt;purl.org/dc/terms/&lt;/a&gt;. The PURL &lt;a href=&quot;http://purl.oclc.org/docs/faq.html&quot;&gt;FAQ&lt;/a&gt; provides a great overview.&lt;/p&gt;
&lt;p&gt;Implementing PURLs for the notebook was very straight-forward. After registering as a user at &lt;a href=&quot;http://purl.org&quot;&gt;purl.org&lt;/a&gt; I applied for my own top-level domain: &lt;code&gt;cboettig&lt;/code&gt;, which I then mapped to my current domain, &lt;a href=&quot;http://carlboettiger.info&quot;&gt;carlboettiger.info&lt;/a&gt; By enabling partial redirects, each page on my site will also be resolved using this top-level domain followed by my existing page structure. Following my existing structure is not necessary – I could map each page to an arbitrary path in my domain, but would have to enter these somewhat manually. While the partial redirect is simpler to implement, it does require that I maintain the rest of the link structure.&lt;/p&gt;
&lt;p&gt;In this way, &lt;a href=&quot;http://purl.org/cboettig/lab-notebook.html&quot;&gt;purl.org/cboettig/lab-notebook.html&lt;/a&gt; now resolves to &lt;a href=&quot;http://carlboettiger.info/lab-notebook.html&quot;&gt;carlboettiger.info/lab-notebook.html&lt;/a&gt;. Likewise, each page in the notebook can be similarly resolved from the purl.org domain instead of my personal carlboettiger.info domain. Should I ever somehow lose control of carlboettiger.info, I could re-assign my PURL to redirect to my new domain URL. This provides DOI-like technology of permanent identifiers for every page in the notebook.&lt;/p&gt;
&lt;h2 id=&quot;github-preserving-content-and-versions&quot;&gt;GitHub: preserving content and versions&lt;/h2&gt;
&lt;p&gt;Committing content to an external repository is the recommended way to avoid link-rot from the user errors and website changes that so frequently plague self-archiving of scholarly content. Keeping multiple copies of content in geographically distinct locations is the time-honored approach of digital archiving. Git and GitHub make this easy. Not only does this mean that a backup copy is publicly available and forkable online, but it is also easy to clone copies on each of the machines I work on and rely on git to keep them in sync. Should Github disappear, a little &lt;code&gt;git remote add&lt;/code&gt; and everything will be effortlessly deployed with complete history elsewhere.&lt;/p&gt;
&lt;p&gt;The notebook has two Github repositories: the “source-code” consisting of plain-text (markdown) content and Jekyll-based templates on &lt;a href=&quot;http://github.com/cboettig/labnotebook&quot;&gt;labnotebook&lt;/a&gt;, and a second for the rendered HTML &lt;a href=&quot;http://github.com/cboettig/cboettig.github.com&quot;&gt;cboettig.github.com&lt;/a&gt; (which also now hosts the website).&lt;/p&gt;
&lt;p&gt;While a custom domain and PURLs provide persistent &lt;em&gt;locators&lt;/em&gt; for the content, distributed copies on Git help archive the content itself. Should my domain vanish or Github disappear, copies of the content, complete with version history, would remain distributed across various machines with a copy of the repository. Links to Github would break in that process, unless we had remapped all links from the notebook to Github using PURLs.&lt;/p&gt;
&lt;h2 id=&quot;greycite-programmatic-access-and-indexing-of-metadata&quot;&gt;Greycite: Programmatic access and indexing of metadata&lt;/h2&gt;
&lt;p&gt;I think of good metadata as the third leg to proper digital archiving, in addition to permanent identifiers and backup of content. We want to be able to point a tool at the permanent identifier / URL of an entry and extract reliable information on the author, time published and last modified, title, author, key words, etc. that might be useful in citing or categorizing the content. Providing this information is really the subject of adding &lt;a href=&quot;http://carlboettiger.info/2012/10/23/semantic-markup-examples-for-the-lab-notebook.html&quot;&gt;Semantic metadata&lt;/a&gt; to the site, and is covered in another entry in this series. Meanwhile, the &lt;a href=&quot;http://greycite.knowledgeblog.org&quot;&gt;Greycite&lt;/a&gt; tool and it’s API are an excellent way to extract this metadata into a variety of useful formats, working much the same way that CrossRef’s tool does using DOIs. Here is an &lt;a href=&quot;http://greycite.knowledgeblog.org/?uri=http%3A%2F%2Fpurl.org%2Fcboettig%2F2012%2F10%2F23%2Fsemantic-markup-examples-for-the-lab-notebook.html&quot;&gt;example query&lt;/a&gt;&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://farm6.staticflickr.com/5325/8940923396_fcf4941197.jpg&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;robust-archiving-with-figshare&quot;&gt;&lt;strong&gt;Robust archiving&lt;/strong&gt; with fig&lt;strong&gt;share&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Depositing a copy of the notebook on fig&lt;strong&gt;share&lt;/strong&gt; is one of the most robust archival solutions of which I am currently aware. Not so much because it has the coveted DOI solution to the permanent identifier problem but because it has the promise of &lt;a href=&quot;http://clocks.org&quot;&gt;CLOCKSS&lt;/a&gt; archiving, should anything ever happen to fig&lt;strong&gt;share&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Nevertheless, it raises several challenges. The native home for the content is as rendered HTML at my domain, not as raw HTML on an archive completely unassociated with that domain, difficult to view, and divorced from my usual workflow, unlike my usual publishing source-code to Github and website to my domain. It also raises questions of just what to archive and when. I discuss some of these strengths and challenges as a separate post, &lt;a href=&quot;http://purl.org/cboettig/2013/05/31/notebook-features-archiving-with-figshare&quot;&gt;archiving the lab notebook on figshare: advantages and challenges&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Digital archiving is a challenging problem that is not completely addressed by any one of these approaches. In the end, robust archiving will be best left in the hands of its experts. Unfortunately, the best examples currently available (such as CLOCKSS, national libraries, etc.) will not archive a researcher’s web page directly. The solutions explored here are not perfect, but they are free and simple to implement. I’d love to hear what others think.&lt;/p&gt;
&lt;h3 id=&quot;see-also&quot;&gt;See also&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.digitalpreservation.gov/ndsa/&quot;&gt;DigitalPreservation.gov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://internetarchive.org&quot;&gt;The Internet Archive&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Archiving the lab notebook on figshare</title>
	 <link href="/2013/05/31/notebook-features-archiving-with-figshare.html"/>
   <updated>2013-05-31T00:00:00+00:00</updated>
   <id>/05/31/notebook-features-archiving-with-figshare</id>
   <content type="html">&lt;h2 id=&quot;robust-archiving-through-clockss&quot;&gt;Robust archiving through CLOCKSS&lt;/h2&gt;
&lt;p&gt;One of the most comprehensive approaches I have come across so far uses fig&lt;strong&gt;share&lt;/strong&gt;. This offers the most promising avenue for content preservation, but is weakest in managing the URIs and associating them with the original content. All fig&lt;strong&gt;share&lt;/strong&gt; content is archived by &lt;a href=&quot;http://clockss.org&quot;&gt;CLOCKSS&lt;/a&gt;, an international library cooperation providing redundant and geopolitically distributed backup of the archives around the world (and used by many academic journals, both subscription based &amp;amp; open access). Should fig&lt;strong&gt;share&lt;/strong&gt; vanish from the face of the planet, it will trigger the release of all of its content to resolve through the CLOCKSS servers, with the same appearance and resolving at the same URLs as the original figshare content. Presumably the DOIs provided to figshare content will also continue to resolve there.&lt;/p&gt;
&lt;h2 id=&quot;challenges&quot;&gt;Challenges&lt;/h2&gt;
&lt;p&gt;It would certainly be preferable to have the notebook archived by CLOCKSS directly, since the association between the original online content at carlboettiger.info is lost in archiving the entries on figshare. More problematically, the content as archived on fig&lt;strong&gt;share&lt;/strong&gt; is not recognized by search engines, etc., as a separate HTML pages to index, but merely as a bundle of attached text files. On the upside, the content becomes part of the global scientific datasets preserved and indexed by fig&lt;strong&gt;share&lt;/strong&gt; with appropriate metadata, etc., increasing the chances for discovery through that venue. Also, fig&lt;strong&gt;share&lt;/strong&gt; provides a convenient API that can help automate deposition.&lt;/p&gt;
&lt;h3 id=&quot;what-content-what-format&quot;&gt;What content? What format?&lt;/h3&gt;
&lt;p&gt;Deciding just what to archive in the fig&lt;strong&gt;share&lt;/strong&gt; database is also less straight forward than it may seem. I have gone through a few iterations:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Archiving the markdown.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Archiving external images with Data URIs.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Archiving the HTML versions of pages alone&lt;/li&gt;
&lt;li&gt;Archiving the whole git repository, &lt;code&gt;_site&lt;/code&gt; HTML included (?)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I began by archiving the markdown files that I write to create each entry. These are plain-text files that can be easily read in any text editor, even if the conventions for rendering them as HTML are lost. Like HTML, figures are linked to external files, and are thus not captured by this solution. To work around this, I adopted the trick of using &lt;a href=&quot;http://carlboettiger.info/2013/01/24/Data-URIs-for-image-archives.html&quot;&gt;Data URIs&lt;/a&gt; to embed images. This places a binary encoding of the image in the text itself, which can be rendered by almost any browser as the appropriate image. While this keeps the content together, the long data URI strings are rather out-of-place inside a plain text document. Further, the markdown loses all of the valuable semantics that are automatically added to each page when Jekyll renders them to HTML. As Phil Lord argues, if there’s any format that future archivists can read successfully – it will be HTML. Consequently I’ve settled on archiving the HTML versions of each notebook entry, with images embedded as Data URIs. Each HTML file contains rich metadata in the header, sidebar, and footer, that give more information about the content and its context in the notebook (relative path, categories and tags, timestamps and SHA hashes, etc). I have archived these entries in annual chunks following the year/month/day directory structure already employed on the site.&lt;/p&gt;
&lt;h3 id=&quot;how-about-site-assets&quot;&gt;How about site assets?&lt;/h3&gt;
&lt;p&gt;There is still additional external content used to render the site – CSS and javascript files – that are not captured in this approach. Though entries actually render &lt;a href=&quot;http://stackoverflow.com/questions/14046738&quot;&gt;just fine without the css&lt;/a&gt;, it would certainly be possible to include this material in the archive (though some Javascript comes from external CDNs). This does make for a bit larger and more cluttered archive, and more to the point is a rather crude solution to a problem already solved by Internet archiving programs such as CLOCKSS or internetarchive.org.&lt;/p&gt;
&lt;h3 id=&quot;versioning&quot;&gt;Versioning?&lt;/h3&gt;
&lt;p&gt;Lastly there is the concern of preserving the version history of entries. Though fig&lt;strong&gt;share&lt;/strong&gt; provides versioning of its content, this doesn’t capture finer resolution of individual page changes available through the Github repository. At the expense of creating an ever more cumbersome archival object, one could include the &lt;code&gt;.git&lt;/code&gt; history, either for the HTML rendered version (which lives at &lt;a href=&quot;https://github.com/cboettig/cboettig.github.com/&quot;&gt;cboettig.github.com&lt;/a&gt;) or the source files used to create it (&lt;a href=&quot;https://github.com/cboettig/labnotebook&quot;&gt;labnotebook&lt;/a&gt;).&lt;/p&gt;
&lt;h3 id=&quot;connecting-to-the-original-instances&quot;&gt;Connecting to the original instances?&lt;/h3&gt;
&lt;p&gt;Of course this fails to address the preservation of externally linked content. The most frequent outbound links point to other publications through, usually their DOIs, which we hope will take care of themselves. The most important externally linked content in the notebook entries are the links to scripts, functions, and manuscripts in the various project repositories on Github. The simplest solution is to embed the most important scripts in the notebook entries themselves. Archiving the project repositories is an additional challenge, but if a user can recover a copy of the project repository (along with it’s &lt;code&gt;.git&lt;/code&gt; history) then it would be possible to identify the linked file using the SHA hash from these links (by matching it against the SHAs in the log). See my entry on &lt;a href=&quot;/2013/05/03/notebook-features-hashes-providing-an-immutable-and-verifiable-research-record.html&quot;&gt;SHA hashes&lt;/a&gt; for more on this topic.&lt;/p&gt;
&lt;h2 id=&quot;links-to-the-archives&quot;&gt;Links to the archives&lt;/h2&gt;
&lt;p&gt;Current and previous archives of my lab notebook can be found on figshare by year. Older versions of these archives have taken a different approach, including just archiving the markdown files. The links use the DOI and point to the most recent version. (At this time linking to explicit versions with FigShare’s DataCite DOI links doesn’t appear to be working)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://dx.doi.org/10.6084/m9.figshare.96916&quot;&gt;Lab Notebook, 2010&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dx.doi.org/10.6084/m9.figshare.96919&quot;&gt;Lab Notebook, 2011&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dx.doi.org/10.6084/m9.figshare.106620&quot;&gt;Lab Notebook, 2012&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Comforting Trends In Scientific Software Use</title>
	 <link href="/2013/05/21/comforting-trends-in-scientific-software-use.html"/>
   <updated>2013-05-21T00:00:00+00:00</updated>
   <id>/05/21/comforting-trends-in-scientific-software-use</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Author’s Note&lt;/strong&gt;: Having refrained from actually posting this for 8 months, as I think I have quite mellowed more my critique. I do believe that education and peer review are the best way forward in tackling these issues, but cannot overstate how much of a long and rocky road that process will be. The Mozilla Science Foundation is really leading these efforts with their code review pilots (as I have discussed in posts since writing this), and through their work with Software Carpentry training. Still, I leave this post as a bookmark of my intial thoughts and a reminder of these challenges.&lt;/p&gt;
&lt;p&gt;Consider reading these other posts on software review and training:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://carlboettiger.info/2013/09/25/mozilla-software-review.html&quot;&gt;Reflections on the Mozilla Code Review Pilot&lt;/a&gt; (phase 1)&lt;/li&gt;
&lt;li&gt;ISEES Meeting software lifecycle: &lt;a href=&quot;http://carlboettiger.info/2013/08/13/ISEES-Day-1.html&quot;&gt;Day 1&lt;/a&gt;, &lt;a href=&quot;http://carlboettiger.info/2013/08/14/ISEES-day-2.html&quot;&gt;Day 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ISEES Software training &lt;a href=&quot;http://carlboettiger.info/2013/09/10/ISEES-training-workshop-day-1.html&quot;&gt;Day 1&lt;/a&gt;, &lt;a href=&quot;http://carlboettiger.info/2013/09/11/ISEES-Workforce-Development-Day-2.html&quot;&gt;Day 2&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://carlboettiger.info/2013/07/09/reviewing-software-revisited.html&quot;&gt;Reviewing Software, revisited&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://carlboettiger.info/2013/06/13/what-I-look-for-in-software-papers.html&quot;&gt;What I look for in software papers&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;I have just been reading through &lt;code&gt;r citet(&amp;quot;10.1126/science.1231535&amp;quot;, &amp;quot;critiques&amp;quot;)&lt;/code&gt;. While I agree with a lot of the sentiment in this article, (we place way too little emphasis on good coding practices, validation, etc.), I actually found this article incredibly frustrating. Following a little &lt;a href=&quot;https://plus.google.com/112929796403983408632/posts/8whV6rtvsuw&quot;&gt;rant on Google+&lt;/a&gt; (G+ has to be good for something, right?) and subsequent discussion, I’ve tried formulating my thoughts into a blog post here.&lt;/p&gt;
&lt;p&gt;What first got my goat were the proposed “solutions” to the problem. I think it is hopelessly naive to write that the solution is “better computational education” and “peer review of code”.&lt;/p&gt;
&lt;h3 id=&quot;calling-for-better-education-is-a-cop-out&quot;&gt;Calling for better education is a cop-out&lt;/h3&gt;
&lt;p&gt;I completely agree that better education is sorely needed, and am delighted to see the authors cite the &lt;a href=&quot;http://softwarecarpentry.org&quot;&gt;Sofware Carpentry&lt;/a&gt; project (Though couldn’t they have made this a proper citations with a link?). However, this is an all too common cop-out of an answer that will do little to address the real problem. For decades such position papers have called for better education to address all our weaknesses – biologists should learn better mathematics, better statistics, better programming skills. They should also learn proper data management and archiving skills no doubt. While we’re at it, they should learn more about communicating science and public speaking too. What these calls to “raise standards” have in common is a &lt;strong&gt;dearth of incentives&lt;/strong&gt;. Reward these talents with jobs and advancement (publications and grants, after all, are just a means to such ends, are they not?) and the education will follow. Economics teaches us that if we want to change behavior, we change incentives. Unless this education translates into the currency of academia, we will only do our students a disservice by forcing it upon them. (I do note that Software Carpentry rightly claims that the kind of training it offers does promise to pay off in the current currency through time savings that will be realized down the line…)&lt;/p&gt;
&lt;h3 id=&quot;peer-review-of-code-is-not-the-answer&quot;&gt;Peer review of code is not the answer&lt;/h3&gt;
&lt;p&gt;If “peer review” were the ultimate solution to good code, we’d see that standard in the software industry too, wouldn’t we? Peer review actually is used in the software industry, if perhaps more the way we treat “friendly review” then with the black-and-white view we attach to peer review in the scientific literature. Peer review would never guarantee the validity of code, though it would certainly help. The real bugbear with peer review of code is just how difficult it would be to establish as a practice. The authors are silent on these challenges: organizing, incentivising, transitioning to, and paying for such a system would all be major hurdles to overcome.&lt;/p&gt;
&lt;p&gt;I would trust software that has a long and active development history with an engaged user base much more than anything that has simply been “peer reviewed”. I suspect that instituting peer review of code in the sciences would be a huge challenge for a potentially limited payoff. If open source taught us nothing else, it is that “with many eyes all bugs are shallow”. Robust software must ultimately rely on bug report feedback cycle of users (and developers following the &lt;a href=&quot;&quot;&gt;“dog food” rule&lt;/a&gt;).&lt;/p&gt;
&lt;h2 id=&quot;so-what-is-the-problem-exactly&quot;&gt;So what is the problem, exactly?&lt;/h2&gt;
&lt;p&gt;If the proposed solutions are weak, the statement of the problem is not actually much more convincing. What, exactly, is the “troubling trend” alluded to in the title? The primary concern from their survey appears to be that scientists rely on personal recommendations, ease of use, and frequency of use in published studies when choosing what software to use. This approach is only “dangerous” if we assume that a scientist has a choice of N potential software applications to perform a task, of which some fraction F are faulty. (And that a “worrying” 80% want to become better programmers…)&lt;/p&gt;
&lt;p&gt;But does this study argue any of the software there users approached was faulty? No. Do they provide evidence that the metrics a researcher uses (popularity, trust, ease of use) are not good predictors of decent software? No! They just assume this can’t possibly be a good criterion to evaluate software.&lt;/p&gt;
&lt;p&gt;Suggesting that this criterion is to blame misses the underlying problem entirely. Researchers will always prefer software that has been used in published studies, is easy to use, and recommended by people they trust. If this is leading to problems, we must fix the software, not the people.&lt;/p&gt;
&lt;p&gt;Reliance on common software is replacing reliance on undisclosed software written from scratch by each researcher. It is much easier to identify and correct errors when the community all uses a common piece of software then when everything is done from scratch. Crucially, this shows the emergence of a common code base – a shared software infrastructure, emerging in many fields. This development is to be celebrated and taken advantage of rather than something to fret over. A shared infrastructure is a powerful thing.&lt;/p&gt;
&lt;h2 id=&quot;real-solutions-changing-incentives&quot;&gt;Real solutions: changing incentives&lt;/h2&gt;
&lt;p&gt;Of course there are some real gems in the paper that should have recieved more emphasis.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Current models for how scientists and journals are rewarded must change, as the would-be editors of the Open Research Computation journal (now a series of the journal Source Code for Biology and Medicine) discovered during efforts to establish a journal for publishing peer-reviewed software ( 27).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Reward software the way we reward papers. Github model of contributions.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Notebook features: SHA Hashes</title>
	 <link href="/2013/05/03/notebook-features-hashes-providing-an-immutable-and-verifiable-research-record.html"/>
   <updated>2013-05-03T00:00:00+00:00</updated>
   <id>/05/03/notebook-features-hashes-providing-an-immutable-and-verifiable-research-record</id>
   <content type="html">&lt;p&gt;Note: this entry is part of a &lt;a href=&quot;http://carlboettiger.info/2013/04/26/notebook-features-introduction.html&quot;&gt;series of posts&lt;/a&gt; which explain some of the technical features of my lab notebook.&lt;/p&gt;
&lt;p&gt;I version manage all changes to my entry using git. Each page is linked to its source history on Github, which will display a list of all previous edits to the post with an easy-to-read commit log and highlighted diffs. A version history is often considered an essential part of an open lab notebook, where changes to the notebook are documented and preserved. While wikis, Google docs, Dropbox, Wordpress plugins, or just regular backups can provide version history of pages, none come close to comparison with a full version management system such as git. This is because git’s underlying architecture is based on&lt;br /&gt;&lt;a href=&quot;http://www-cs-students.stanford.edu/~blynn/gitmagic/ch08.html&quot;&gt;The magic of cryptographic SHA hashes&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hashes provide an immutable and verifiable record of any all changes I make. Because the hash is generated by the cryptographic SHA1 algorithm from the contents of the site, it is impossible to make changes without causing the hash to update. By referencing the content’s hash value we can be sure to link to a constant version of the entry. These can be verified by re-generating the hash (requiring the previous state of the repository in this case, see note below). Unlike publication timestamps, versions, or DOIs, this provides a way not only to reference particular versions of a file, but a cryptographically secure way to &lt;em&gt;verify&lt;/em&gt; that the version is what it claims to be. &lt;a href=&quot;http://www.tkuhn.ch/&quot;&gt;Tobias Kuhn&lt;/a&gt; has &lt;a href=&quot;http://www.force11.org/node/4301&quot;&gt;observed&lt;/a&gt; that this is a valuable feature we should want to see for all scientific publishing. Each of my posts now displays its SHA hash on the sidebar along with other metadata. While the &lt;code&gt;history&lt;/code&gt; button already provides a convenient way to browse all previous versions of a post, I chose to display the SHA hash directly so that the hash value would be part of the document metadata, while also highlighting this feature.&lt;/p&gt;
&lt;p&gt;In addition to the GitHub repository for my lab notebook, My research code, analyses, and manuscripts are collected into Github repositories by project. This allows my analysis and paper writing to benefit from this same immutable and verifiable record. Because GitHub uses the SHA hashes in its link structure, this also provides a convenient way to link to a particular version of code in a given entry. This way, I can be sure the contents of the file displayed at that link never change, even as I continue to update that file. Even if the file or containing directory is later deleted or moved, the link will still resolve. Only if the entire project repo were deleted or if Github itself dissolved would the link be lost. Even then, using the SHA hash given in the link we could determine the contents of the file from some other copy of the repository (such as a local or figshare archive).&lt;/p&gt;
&lt;p&gt;Tobias is actually working on his own SHA hash approach which is somewhat superior to the simpler method of using git. The Github hash corresponds to the state of the entire repository/notebook at the time of the commit, rather than the contents of an individual file. Consequently, one would need a snapshot of the entire repository, available on Github, to perform the verification. Tobias is looking into generating hashes based on the contents of the file directly – so far, only RDF data – that could provide a unique and verifiable reference for any scholarly data or publication.&lt;/p&gt;
&lt;p&gt;Version managing the notebook and code has many more practical day-to-day benefits, such as recovering from a mistaken deleted or corrupted file, merging changes made on different machines or by collaborators, or creating branches to test new features without disrupting current version, and comparing differences as a file evolves.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Scholarly Infrastructure Thoughts</title>
	 <link href="/2013/05/02/scholarly-infrastructure-thoughts.html"/>
   <updated>2013-05-02T00:00:00+00:00</updated>
   <id>/05/02/scholarly-infrastructure-thoughts</id>
   <content type="html">&lt;h2 id=&quot;sustainable-research&quot;&gt;Sustainable Research&lt;/h2&gt;
&lt;p&gt;Happened across a provocative &lt;a href=&quot;http://cran.r-project.org/web/packages/mcmc/ChangeLog&quot;&gt;example&lt;/a&gt; of why we need a software ecosystem, though it was certainly not intended to be one, which led me to ask myself:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How complex does an algorithm have to be before a talented researcher with expertise in both the relevant mathematics and computer science will make a significant mistake in their first release of the software?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As a corollary we might also ask, “How much less care do we put into research code not destined for release?”&lt;/p&gt;
&lt;p&gt;This changelog clearly reflects these difficulties face well-established researchers with long publication records on these very methods. If such individuals can make mistakes in packages, are we supposed to trust the myriad personal implementations of this and more complex algorithms that bulwark our literature today?&lt;/p&gt;
&lt;p&gt;Academic knowledge is currently built in the mortar and bricks of publication and citation. Publications advance new claims built up on existing claims (and very occasionally replacing them) through citations. It an approach that does not scale well on many fronts. To verify information we must trace the citation chain, which grows far to quickly to for human processing and is not usually amenable to computer processing. Yet here it is the statistical scaling that concerns me more – a paper advances that a claim is true with a certain probability, given that the methods are implemented without error. The more publications we string together, the higher the probability that we observe false positives, but also that we observe implementation errors. For much of research today, we need not construct the scientific argument in this manner.&lt;/p&gt;
&lt;p&gt;Thanks to computational advances of the last several decades, public repositories of the data and the methods (such as can be implemented as software anyway), we can build on existing work by direct analysis of the data and methods, rather than treating the conclusions as given. Evidence would no longer come primarily in the highly circumstantial manner of citations to previous claims, but to direct analysis of data. Using a common pool of data and methods would align incentives better to maintain and improve upon this infrastructure (the way major companies contribute to the underlying ‘plumbing’ provided by shared open source infrastructure), while there is no incentive for the literature to work in such a way.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://cameronneylon.net/blog/whats-the-right-model-for-shared-scholarly-communications-infrastructure&quot;&gt;Cameron Neylon&lt;/a&gt;, and link in my comment.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Musings On Conservation Literature</title>
	 <link href="/2013/05/02/musings-on-conservation-literature.html"/>
   <updated>2013-05-02T00:00:00+00:00</updated>
   <id>/05/02/musings-on-conservation-literature</id>
   <content type="html">&lt;p&gt;Just because I’m a theorist deeply entrenched in methodological concerns about uncertainty and decision making doesn’t mean I don’t think about practical conservation from time to time. Some musings from my &lt;a href=&quot;http://dynamicecology.wordpress.com/2013/04/29/the-implementation-gap-in-conservation-biology-is-math-contributing-to-the-problem&quot;&gt;comment here&lt;/a&gt;, copied over for my own reference.&lt;/p&gt;
&lt;p&gt;Though I would like to believe the gap stems from the problems you discuss, I think that differing objectives between research and application may play a much larger role. I suspect that scientific papers that are most useful and influential for conservation practitioners and policymakers are those which confirm what they already believe, or whatever the interests opposed to them least want to hear. Let’s call these “Cassandra” papers, since in this context they usually forecast disaster. For the practitioner it may matters little whether the math is simple or complex, clearly explained or impenetrable, or even right or not so right. Worm et al 2006 paper which the media quickly decided predicted the end of global fisheries within 50 years is perhaps a good example.&lt;/p&gt;
&lt;p&gt;Okay, so beyond bolstering arguments already being made by those who propose, implement or legislate conservation against their opposition, there are certainly unknowns that they might turn to research to answer. Resource allocation might be an example of this; e.g. do we prioritize purchasing pristine areas that are not likely to be threatened or less pristine areas in more immediate danger (a la Pfaff). Let’s call these “rule of thumb” papers, where the conclusion is an easily applied guide-line. It seems doubtful that the practitioners would be inhibited by their access and understanding of the math in this case, since they want the research to provide an answer they can trust, and not worry so much about what math justifies it. They are more likely to use proxies of quality (journal, researcher, affiliation, popularity of the method), then working through the assumptions to see if they like them; no?&lt;/p&gt;
&lt;p&gt;So there is a third case in which the conclusion is of the sort “apply my method and it will tell you what to do”, as opposed to “here’s what to do”. I think only this case falls at risk to the mathematics being a barrier, though when accompanied by user-friendly software tools perhaps that can be dismissed as well. These “methods” papers are probably the favorite option of many researchers, as they seem the most rigorous, accurate way, reflecting the details of the problem at hand. Scientists are probably least fond of the first example, where even the paper’s authors may feel the conclusions are being overstated, while others feel such work is wrong and counterproductive. I’d guess many researchers are lukewarm towards the middle case, as better than a coin flip. I imagine from the conservation practitioner’s ranking is reversed. To what extent would you agree with this classification? If so, how is the conservation literature distributed across these categories, and how might we want it to be distributed? Do we indeed have the greatest impact writing Cassandra papers rather than writing nice clear methods, and if so, what are the implications?&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Notebook features: reproducible code</title>
	 <link href="/2013/04/26/notebook-features-reproducible-code.html"/>
   <updated>2013-04-26T00:00:00+00:00</updated>
   <id>/04/26/notebook-features-reproducible-code</id>
   <content type="html">&lt;p&gt;I now use the dynamic documentation software called &lt;a href=&quot;http://yihui.name/knitr&quot;&gt;knitr&lt;/a&gt; to write most entries that shore results and figures. The code to replicate the results is included automatically, ensuring that what I say I did and what code I actually ran to get the results are consistent. Though I have written about knitr before, both regarding its &lt;a href=&quot;http://carlboettiger.info/2012/03/21/knitr-github-and-a-new-phase-for-the-lab-notebook.html&quot;&gt;use in my notebook&lt;/a&gt; and &lt;a href=&quot;http://carlboettiger.info/2012/04/07/writing-reproducibly-in-the-open-with-knitr.html&quot;&gt;in my manuscripts&lt;/a&gt;, here I provide a quick summary of how a reader might actually reproduce a figure or result they come across in the notebook, as well as some of the possible problems involved.&lt;/p&gt;
&lt;p&gt;As the code required for any given analysis can be quite involved, it is not pratical to provide free-standing scripts in this way. Instead, I write the algorithms as functions provided by an R package dedicated to the project, e.g. &lt;a href=&quot;http://github.com/cboettig/nonparametric-bayes&quot;&gt;nonparametric-bayes&lt;/a&gt;, &lt;a href=&quot;http://github.com/cboettig/multiple_uncertainty&quot;&gt;multiple-uncertainty&lt;/a&gt;, or &lt;a href=&quot;http://github.com/cboettig/earlywarning&quot;&gt;warning-signals&lt;/a&gt;, which is version-managed on Github. The code displayed in the post can then be limited to the specific calls to analysis, data manipulation, and plotting functions unique to the exploration shown, without repeating the code for all algorithms involved.&lt;/p&gt;
&lt;p&gt;The code for the analyses is also stored on github using the same dynamic documentation approach with knitr. These scripts are found in the &lt;code&gt;inst/examples&lt;/code&gt; directory of my packages. This approach allows a given analysis to evolve with my research in a more tractable way than simply pasting updated copies as successive notebook entries. The notebook entries then become a place for me to synthesize the results of a script.&lt;/p&gt;
&lt;p&gt;Though the package functions are usually backwards-compatible, proper reproducibility is only attained by having the version of the package from time of the result. This is easily accomplished by the seemless integration of Github and R using the devtools package. Consider a figure from a page of the notebook, such as the final histogram plot from &lt;a href=&quot;http://www.carlboettiger.info/2012/12/20/results-comparing-gp-to-parametric.html&quot;&gt;this entry&lt;/a&gt;. The entry links to the script responsible for the figure, &lt;a href=&quot;https://github.com/cboettig/nonparametric-bayes/blob/9d5cd1f027bdfe5f356dce83756726c95a6fcdd8/inst/examples/myers-exploration.md&quot; class=&quot;uri&quot;&gt;https://github.com/cboettig/nonparametric-bayes/blob/9d5cd1f027bdfe5f356dce83756726c95a6fcdd8/inst/examples/myers-exploration.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We can install the entire research compendium at exactly the state it was at the time of the analysis using the hash (long chain of seemingly random characters, see the (upcoming) entry on &lt;a href=&quot;&quot;&gt;hashes&lt;/a&gt;) using the clever &lt;code&gt;devtools&lt;/code&gt; R package,&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;install_github&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;nonparametric-bayes&amp;quot;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;cboettig&amp;quot;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;9d5cd1f027bdfe5f356dce83756726c95a6fcdd8&amp;quot;&lt;/span&gt;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then copy and paste the code linked from the figure to replicate the results. This provides a fast and effective way replicate the work appearing in or linked to any entry. More importantly perhaps, this approach also allows one to repeat any given analysis with the most recent version of an algorithm and compare the results, since the package structure provides a logical seperation between algorithm and analysis. In practice such fine-grained control and invistigation is more important than simply being able to regenerate what has already been done without any further input.&lt;/p&gt;
&lt;p&gt;This is not entirely failsafe. The package may depend on other packages, which themselves may have changed. For my use cases, it is a deal more reliable than running the current version of a package that is actively changing during my research. Readers interested in even more robust replication and verification should take a look at Roger Peng’s package &lt;code&gt;stashR&lt;/code&gt; package and associated publications &lt;span class=&quot;showtooltip&quot; data-html=&quot;true&quot; title=&quot;&lt;p&gt;Eckel S and Peng RD (2012). stashR: A Set of Tools for Administering SHared Repositories. R package version 0.3-5.“&amp;gt;&lt;a href=&quot;http://CRAN.R-project.org/package=stashR&quot;&gt;Eckel &amp;amp; Peng (2012)&lt;/a&gt;&lt;/span&gt; .&lt;/p&gt;
&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Sandy Eckel, Roger Peng, (2012) stashR: A Set of Tools for Administering SHared Repositories. &lt;a href=&quot;http://CRAN.R-project.org/package=stashR&quot; class=&quot;uri&quot;&gt;http://CRAN.R-project.org/package=stashR&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Notebook features: an introduction</title>
	 <link href="/2013/04/26/notebook-features-introduction.html"/>
   <updated>2013-04-26T00:00:00+00:00</updated>
   <id>/04/26/notebook-features-introduction</id>
   <content type="html">&lt;p&gt;In keeping this open lab notebook, I have sought to address three goals (in addition to all the traditional reasons for keeping a lab notebook)&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Provide an educational resource&lt;/li&gt;
&lt;li&gt;Experiment with scientific infrastructure and tools for sharing and replicating research&lt;/li&gt;
&lt;li&gt;Facilitate the rapid and open dissemination of scientific research&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;which are coincidentally evocative of &lt;a href=&quot;http://www.nsf.gov/pubs/2007/nsf07046/nsf07046.jsp&quot;&gt;NSF’s Broader Impacts&lt;/a&gt; areas. In this series of posts I plan to explore and illustrate some of my experiments to address these goals through various web-based tools available for an open notebook platform. Many of these have been documented in the notebook itself as I experiment with them (see &lt;a href=&quot;http://www.carlboettiger.info/tags.html#notebook-technology&quot;&gt;#notebook-technology&lt;/a&gt;). Not all of those experiments pan out and older tools and techniques are often replaced with newer ones as I explore, and these posts are usually more technical notes written to help me think through and remember what I’m trying out. In order to provide a more accessible snapshot of notebook features, I thought it might be helpful to write a series of posts describing these tools and techniques.&lt;/p&gt;
&lt;p&gt;Below is an index of posts in this theme that I will continue to update as I have a chance to finish them. If there’s anything about the notebook that you’d like to hear more about, feel free to suggest it in the comments.&lt;/p&gt;
&lt;h3 id=&quot;written&quot;&gt;Written&lt;/h3&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;a href=&quot;http://carlboettiger.info/2013/04/26/notebook-features-reproducible-code.html&quot;&gt;Reproducible code: embedding code and dynamic documents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://carlboettiger.info/2013/04/04/notebook-parsing.html&quot;&gt;Parsing linked data in the semantic notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://carlboettiger.info/2013/05/03/notebook-features-hashes-providing-an-immutable-and-verifiable-research-record.html&quot;&gt;Hashes: An immutable and verifiable record of research&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://carlboettiger.info/2013/05/31/notebook-features-digital-archiving.html&quot;&gt;Digital archiving&lt;/a&gt;. See also a separate entry on &lt;a href=&quot;http://purl.org/cboettig/2013/05/31/notebook-features-archiving-with-figshare&quot;&gt;advantages and challenges in archiving with figshare&lt;/a&gt;, and some &lt;a href=&quot;/2013/06/03/DOI-citable.html&quot;&gt;comments about DOIs&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;planned&quot;&gt;Planned&lt;/h3&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;a href=&quot;&quot;&gt;Readable, multi-device typography&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;&quot;&gt;Notebook analytics: Who reads this stuff anyway?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;&quot;&gt;A fast, inexpensive, and scalable online platform&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;&quot;&gt;Online notebook essentials: link, tag, search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;&quot;&gt;Integrating social networks with the notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;…&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Notebook Features: parsing linked data in the semantic notebook</title>
	 <link href="/2013/04/04/notebook-parsing.html"/>
   <updated>2013-04-04T00:00:00+00:00</updated>
   <id>/04/04/notebook-parsing</id>
   <content type="html">&lt;p&gt;In a &lt;a href=&quot;/2011/05/08/building-a-semantic-notebook.html&quot;&gt;post a while back&lt;/a&gt; I originally put forward the idea of a semantic lab notebook. Semantics, or linked data, are among the most powerful concepts to emerge in online science for scholarly data organization and communication. I have slowly been adding and exploring new ways to introduce semantic concepts into the notebook, which I have documented along the way under my &lt;a href=&quot;http://www.carlboettiger.info/tags.html#semantics&quot;&gt;#semantics&lt;/a&gt; tag. In this post, rather than discuss how to generate the semantic data, I try to focus on some of the things we can &lt;em&gt;do&lt;/em&gt; with it. This really just scratches the surface of possibilities, but should at least illustrate the general idea.&lt;/p&gt;
&lt;p&gt;We will start with some very simple examples exploiting the semantics inherent in HTML5. We can then work up to richer examples that rely on XML-based parsing. The richest potential of the semantic notebook lies in leveraging the RDFa content, whose terms are defined as ontologies over which a machine can apply reasoning and formal logic against other web content (see, e.g. &lt;span class=&quot;showtooltip&quot; title=&quot;Shadbolt N, Berners-Lee T and Hall W (2006). The Semantic Web
Revisited. _Ieee Intelligent Systems_, *21*, pp. 96-101. ISSN
1541-1672,  http://dx.doi.org/10.1109/MIS.2006.62.&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1109/MIS.2006.62&quot; rel=&quot;http://purl.org/spar/cito/obtainsBackgroundFrom&quot; &gt;Shadbolt &lt;em&gt;et. al.&lt;/em&gt; (2006)&lt;/a&gt;&lt;/span&gt; for further unformation). Though we show how to extract the and parse the RDF here, exploiting the RDF in the last example must wait to a later post.&lt;/p&gt;
&lt;h2 id=&quot;parsing-semantic-html&quot;&gt;Parsing semantic HTML&lt;/h2&gt;
&lt;p&gt;Our first set of examples will address parsing the semantic HTML directly. For background on how these elements are added to the notebook, see &lt;a href=&quot;/2012/10/14/semantic-lab-notebook.html&quot;&gt;this entry&lt;/a&gt;. We will use R with it’s excellent collection of web, XML parsing, and text-mining tools to take advantage of the semantic structure. First we load the required packages,&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(RCurl)
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(XML)
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(tm)
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(wordcloud)
&lt;span class=&quot;kw&quot;&gt;library&lt;/span&gt;(RColorBrewer)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can get a list of pages to download from the sitemap&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;pagelist &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;readLines&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;http://carlboettiger.info/sitemap.txt&amp;quot;&lt;/span&gt;)
pagelist &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;pagelist[&lt;span class=&quot;kw&quot;&gt;grep&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;/201&lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;d/&amp;quot;&lt;/span&gt;, pagelist)]  &lt;span class=&quot;co&quot;&gt;# drop non-posts)&lt;/span&gt;
pages &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;lapply&lt;/span&gt;(pagelist, getURLContent, &lt;span class=&quot;dt&quot;&gt;followlocation =&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or, if an archive is available locally, (e.g. from figshare cache), we can read the files in directly.&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;pages &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;system&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;ls ~/Documents/labnotebook/_site/2***/*/*/*.html&amp;quot;&lt;/span&gt;, 
    &lt;span class=&quot;dt&quot;&gt;intern =&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We parse each of the pages as HTML so that we can manipulate them with XML tools&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;html &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;lapply&lt;/span&gt;(pages, htmlParse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For instance, we can easily get the content of all entries:&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;text &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sapply&lt;/span&gt;(html, xpathSApply, &lt;span class=&quot;st&quot;&gt;&amp;quot;//article&amp;quot;&lt;/span&gt;, xmlValue)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also extract metadata based on the semantic markup.&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;titles &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sapply&lt;/span&gt;(html, xpathSApply, &lt;span class=&quot;st&quot;&gt;&amp;quot;//title&amp;quot;&lt;/span&gt;, xmlValue)
categories &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sapply&lt;/span&gt;(html, xpathSApply, &lt;span class=&quot;st&quot;&gt;&amp;quot;//node()[@class=&amp;#39;category&amp;#39;]&amp;quot;&lt;/span&gt;, 
    xmlValue)
tags &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sapply&lt;/span&gt;(html, xpathSApply, &lt;span class=&quot;st&quot;&gt;&amp;quot;//node()[@class=&amp;#39;tag&amp;#39;]&amp;quot;&lt;/span&gt;, xmlValue)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R makes it easy to summarize this data, e.g. by generating a table of the number of entries in each category, or a wordcloud of the tags.&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;table&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;unlist&lt;/span&gt;(categories))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
 computation      ecology    evolution open-science     teaching 
          40          376          287           85           17 &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;wordcloud&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;Corpus&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;VectorSource&lt;/span&gt;(tags)))&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&quot;http://farm9.staticflickr.com/8258/8620398951_0c2fd56e26_o.png&quot; /&gt;
&lt;/figure&gt;
&lt;h3 id=&quot;extracting-citations&quot;&gt;Extracting citations&lt;/h3&gt;
&lt;p&gt;Citation information can be encoded&lt;/p&gt;
&lt;p&gt;We can perform more direct text mining as well. For instance, we extract all DOIs found in the text:&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;doi_pattern =&lt;span class=&quot;st&quot;&gt; &amp;quot;&lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![&lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;amp;&amp;#39;&amp;lt;&amp;gt;])&lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;S)+)&lt;/span&gt;&lt;span class=&quot;ch&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;b&amp;quot;&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;require&lt;/span&gt;(gsubfn)
dois &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;strapply&lt;/span&gt;(text, doi_pattern, &lt;span class=&quot;dt&quot;&gt;perl =&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)  &lt;span class=&quot;co&quot;&gt;#text[-462]&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;head&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;sort&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;table&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;unlist&lt;/span&gt;(dois))))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
10.1002/(SICI)1520-6602(1998)1:1                 10.1002/bjs.6880 
                               1                                1 
                10.1002/etc.2140           10.1006/jtbi.1998.0660 
                               1                                1 
          10.1006/jtbi.2000.1080           10.1006/jtbi.2001.2299 
                               1                                1 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or generate a wordcloud of the full text&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;
carl &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;Corpus&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;VectorSource&lt;/span&gt;(text))
carl &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;tm_map&lt;/span&gt;(carl, removePunctuation)
carl &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;tm_map&lt;/span&gt;(carl, tolower)
carl &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;tm_map&lt;/span&gt;(carl, function(x) &lt;span class=&quot;kw&quot;&gt;removeWords&lt;/span&gt;(x, &lt;span class=&quot;kw&quot;&gt;stopwords&lt;/span&gt;()))

carl.tdm &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;TermDocumentMatrix&lt;/span&gt;(carl)
carl.m &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;as.matrix&lt;/span&gt;(carl.tdm)
carl.v &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;sort&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;rowSums&lt;/span&gt;(carl.m), &lt;span class=&quot;dt&quot;&gt;decreasing =&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)
carl.d &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;data.frame&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;word =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;names&lt;/span&gt;(carl.v), &lt;span class=&quot;dt&quot;&gt;freq =&lt;/span&gt; carl.v)


&lt;span class=&quot;kw&quot;&gt;wordcloud&lt;/span&gt;(carl.d$word, carl.d$freq, &lt;span class=&quot;dt&quot;&gt;scale =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;, &lt;span class=&quot;fl&quot;&gt;0.4&lt;/span&gt;), &lt;span class=&quot;dt&quot;&gt;min.freq =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, 
    &lt;span class=&quot;dt&quot;&gt;max.words =&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;random.order =&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;rot.per =&lt;/span&gt; &lt;span class=&quot;fl&quot;&gt;0.15&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;colors =&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;brewer.pal&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;, 
        &lt;span class=&quot;st&quot;&gt;&amp;quot;Dark2&amp;quot;&lt;/span&gt;))&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&quot;http://farm9.staticflickr.com/8385/8621498714_2fe3e04226_o.png&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;rdfa-parsing&quot;&gt;RDFa parsing&lt;/h2&gt;
&lt;p&gt;RDF triples are the mainstay of semantic, linked data. Unlike the more text-mining oriented examples above, data in this format follows a strict and universal standard which allows a machine to identify meaning rather precisely. Critically, this allows one to automatically link data appearing in the notebook to data elsewhere on the web without the ambiguities of natural language that for instance, might confuse the animal jaguar with the car.&lt;/p&gt;
&lt;p&gt;RDFa is a way of adding these precise statements to HTML, again see the &lt;a href=&quot;/2012/10/14/semantic-lab-notebook.html&quot;&gt;earlier entry&lt;/a&gt; on how this is done. The technically inclined will note that the namespaces of the RDFa itself are not accessible in the XML parsing we used above, since they do not correspond to nodes or attributes, but appear only in the values of attributes. Fortunately, there are many excellent tools to extract this RDFa data, turning it into the XML formatted RDF triples we need. e can perform this using the &lt;a href=&quot;http://any23.org&quot;&gt;Any23&lt;/a&gt; API&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;download.file&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;paste&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;http://any23.org/rdfxml&amp;quot;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;http://carlboettiger.info&amp;quot;&lt;/span&gt;, 
    &lt;span class=&quot;dt&quot;&gt;sep =&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;/&amp;quot;&lt;/span&gt;), &lt;span class=&quot;st&quot;&gt;&amp;quot;temp.xml&amp;quot;&lt;/span&gt;)
doc &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;xmlParse&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;temp.xml&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which creates a beautiful RDF XML file of all linked data found in the entry.&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;doc&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;rdf:RDF xmlns:xhtml=&amp;quot;http://www.w3.org/1999/xhtml/vocab#&amp;quot; xmlns:dcterms=&amp;quot;http://purl.org/dc/terms/&amp;quot; xmlns:rdf=&amp;quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&amp;quot;&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://www.carlboettiger.info/&amp;quot;&amp;gt;
    &amp;lt;dcterms:title xml:lang=&amp;quot;en&amp;quot;&amp;gt;Carl Boettiger&amp;lt;/dcterms:title&amp;gt;
    &amp;lt;xhtml:license rdf:resource=&amp;quot;http://creativecommons.org/publicdomain/zero/1.0/&amp;quot;/&amp;gt;
    &amp;lt;dcterms:title xml:lang=&amp;quot;en&amp;quot;&amp;gt;Carl Boettiger&amp;lt;/dcterms:title&amp;gt;
    &amp;lt;dcterms:creator xml:lang=&amp;quot;en&amp;quot;&amp;gt;Carl Boettiger&amp;lt;/dcterms:creator&amp;gt;
    &amp;lt;dcterms:date xml:lang=&amp;quot;en&amp;quot;&amp;gt;2013-04-04T11:07:14-07:00&amp;lt;/dcterms:date&amp;gt;
    &amp;lt;dcterms:format xml:lang=&amp;quot;en&amp;quot;&amp;gt;text/html&amp;lt;/dcterms:format&amp;gt;
    &amp;lt;dcterms:language xml:lang=&amp;quot;en&amp;quot;&amp;gt;en&amp;lt;/dcterms:language&amp;gt;
    &amp;lt;dcterms:identifier xml:lang=&amp;quot;en&amp;quot;&amp;gt;/index.html&amp;lt;/dcterms:identifier&amp;gt;
    &amp;lt;dcterms:rights xml:lang=&amp;quot;en&amp;quot;&amp;gt;CC0&amp;lt;/dcterms:rights&amp;gt;
    &amp;lt;dcterms:source xml:lang=&amp;quot;en&amp;quot;&amp;gt;Lab Notebook&amp;lt;/dcterms:source&amp;gt;
    &amp;lt;dcterms:subject xml:lang=&amp;quot;en&amp;quot;&amp;gt;Ecology&amp;lt;/dcterms:subject&amp;gt;
    &amp;lt;dcterms:type xml:lang=&amp;quot;en&amp;quot;&amp;gt;website&amp;lt;/dcterms:type&amp;gt;
    &amp;lt;title xmlns=&amp;quot;http://ogp.me/ns#&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;Carl Boettiger&amp;lt;/title&amp;gt;
    &amp;lt;author xmlns=&amp;quot;http://ogp.me/ns#&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;http://www.carlboettiger.info/index.html#me&amp;lt;/author&amp;gt;
    &amp;lt;first_name xmlns=&amp;quot;http://ogp.me/ns/profile#&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;Carl&amp;lt;/first_name&amp;gt;
    &amp;lt;last_name xmlns=&amp;quot;http://ogp.me/ns/profile#&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;Boettiger&amp;lt;/last_name&amp;gt;
    &amp;lt;published_time xmlns=&amp;quot;http://ogp.me/ns/article#&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;2013-04-04T11:07:14-07:00&amp;lt;/published_time&amp;gt;
    &amp;lt;site_name xmlns=&amp;quot;http://ogp.me/ns#&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;Lab Notebook&amp;lt;/site_name&amp;gt;
    &amp;lt;url xmlns=&amp;quot;http://ogp.me/ns#&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;http://www.carlboettiger.info/index.html&amp;lt;/url&amp;gt;
    &amp;lt;type xmlns=&amp;quot;http://ogp.me/ns#&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;website&amp;lt;/type&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://carlboettiger.info#me&amp;quot;&amp;gt;
    &amp;lt;rdf:type rdf:resource=&amp;quot;http://xmlns.com/foaf/0.1/Person&amp;quot;/&amp;gt;
    &amp;lt;rdf:type rdf:resource=&amp;quot;http://schema.org/Person#Person&amp;quot;/&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://www.carlboettiger.info/assets/img/carlboettiger.png&amp;quot;&amp;gt;
    &amp;lt;depiction xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; xml:lang=&amp;quot;en&amp;quot;/&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://carlboettiger.info&amp;quot;&amp;gt;
    &amp;lt;homepage xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; rdf:resource=&amp;quot;http://carlboettiger.info&amp;quot;/&amp;gt;
    &amp;lt;url xmlns=&amp;quot;http://schema.org/Person#&amp;quot; rdf:resource=&amp;quot;http://carlboettiger.info&amp;quot;/&amp;gt;
    &amp;lt;name xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;Carl Boettiger&amp;lt;/name&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://carlboettiger.info#me&amp;quot;&amp;gt;
    &amp;lt;jobTitle xmlns=&amp;quot;http://schema.org/Person#&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;a post-doctoral researcher&amp;lt;/jobTitle&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:nodeID=&amp;quot;node17eprp1n4x899515&amp;quot;&amp;gt;
    &amp;lt;rdf:type rdf:resource=&amp;quot;http://xmlns.com/foaf/0.1/Person&amp;quot;/&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://carlboettiger.info#me&amp;quot;&amp;gt;
    &amp;lt;knows xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; rdf:nodeID=&amp;quot;node17eprp1n4x899515&amp;quot;/&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:nodeID=&amp;quot;node17eprp1n4x899515&amp;quot;&amp;gt;
    &amp;lt;homepage xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; rdf:resource=&amp;quot;http://users.soe.ucsc.edu/~msmangel/&amp;quot;/&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://carlboettiger.info#me&amp;quot;&amp;gt;
    &amp;lt;knows xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; rdf:nodeID=&amp;quot;node17eprp1n4x899515&amp;quot;/&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://users.soe.ucsc.edu/~msmangel/&amp;quot;&amp;gt;
    &amp;lt;name xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;Marc Mangel&amp;lt;/name&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:nodeID=&amp;quot;node17eprp1n4x899516&amp;quot;&amp;gt;
    &amp;lt;rdf:type rdf:resource=&amp;quot;http://xmlns.com/foaf/0.1/Person&amp;quot;/&amp;gt;
    &amp;lt;homepage xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; rdf:resource=&amp;quot;http://swfsc.noaa.gov/staff.aspx?&amp;amp;amp;id=17294&amp;quot;/&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://swfsc.noaa.gov/staff.aspx?&amp;amp;amp;id=17294&amp;quot;&amp;gt;
    &amp;lt;name xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;Steve Munch&amp;lt;/name&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://carlboettiger.info#me&amp;quot;&amp;gt;
    &amp;lt;affiliation xmlns=&amp;quot;http://schema.org/Person#&amp;quot; rdf:resource=&amp;quot;http://boe.ucsc.edu/~msmangel/CSTAR.html&amp;quot;/&amp;gt;
    &amp;lt;workplaceHomepage xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; rdf:resource=&amp;quot;http://www.ucsc.edu/&amp;quot;/&amp;gt;
    &amp;lt;weblog xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; rdf:resource=&amp;quot;http://www.carlboettiger.info/lab-notebook.html&amp;quot;/&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:nodeID=&amp;quot;node17eprp1n4x899517&amp;quot;&amp;gt;
    &amp;lt;rdf:type rdf:resource=&amp;quot;http://schema.org/PostalAddress&amp;quot;/&amp;gt;
    &amp;lt;address xmlns=&amp;quot;http://schema.org/Person#&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;Center for Stock Assessment Research, 110 Shaffer Rd, Santa Cruz, CA 95050, USA&amp;lt;/address&amp;gt;
    &amp;lt;streetAddress xmlns=&amp;quot;http://schema.org/PostalAddress/&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;Center for Stock Assessment Research, 110 Shaffer Rd&amp;lt;/streetAddress&amp;gt;
    &amp;lt;addressLocality xmlns=&amp;quot;http://schema.org/PostalAddress/&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;Santa Cruz&amp;lt;/addressLocality&amp;gt;
    &amp;lt;addressRegion xmlns=&amp;quot;http://schema.org/PostalAddress/&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;CA&amp;lt;/addressRegion&amp;gt;
    &amp;lt;postalCode xmlns=&amp;quot;http://schema.org/PostalAddress/&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;95050&amp;lt;/postalCode&amp;gt;
    &amp;lt;addressCountry xmlns=&amp;quot;http://schema.org/PostalAddress/&amp;quot; xml:lang=&amp;quot;en&amp;quot;&amp;gt;USA&amp;lt;/addressCountry&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;https://orcid.org/0000-0002-1642-628X&amp;quot;&amp;gt;
    &amp;lt;orcid xmlns=&amp;quot;http://purl.org/spar/datacite/&amp;quot; rdf:resource=&amp;quot;https://orcid.org/0000-0002-1642-628X&amp;quot;/&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://www.carlboettiger.info#me&amp;quot;&amp;gt;
    &amp;lt;rdf:type rdf:resource=&amp;quot;http://xmlns.com/foaf/0.1/Person&amp;quot;/&amp;gt;
    &amp;lt;account xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; rdf:resource=&amp;quot;http://www.cloudflare.com/email-protection#f497969b9180809d93b49399959d98da979b99&amp;quot;/&amp;gt;
    &amp;lt;account xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; rdf:resource=&amp;quot;https://twitter.com/cboettig&amp;quot;/&amp;gt;
    &amp;lt;account xmlns=&amp;quot;http://xmlns.com/foaf/0.1/&amp;quot; rdf:resource=&amp;quot;https://github.com/cboettig&amp;quot;/&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
  &amp;lt;rdf:Description rdf:about=&amp;quot;http://www.carlboettiger.info/&amp;quot;&amp;gt;
    &amp;lt;license xmlns=&amp;quot;http://www.carlboettiger.info/&amp;quot; rdf:resource=&amp;quot;http://creativecommons.org/publicdomain/zero/1.0/&amp;quot;/&amp;gt;
    &amp;lt;license xmlns=&amp;quot;http://creativecommons.org/ns#&amp;quot; rdf:resource=&amp;quot;http://creativecommons.org/publicdomain/zero/1.0/&amp;quot;/&amp;gt;
  &amp;lt;/rdf:Description&amp;gt;
&amp;lt;/rdf:RDF&amp;gt;
 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now explore this data using the XML tools illustrated above. The rigidity of the XML rather than HTML parsing and the use of namespaces gives us greater precision.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Semantic Citations For The Notebook And Knitr</title>
	 <link href="/2013/02/22/semantic-citations-for-the-notebook-and-knitr.html"/>
   <updated>2013-02-22T00:00:00+00:00</updated>
   <id>/02/22/semantic-citations-for-the-notebook-and-knitr</id>
   <content type="html">&lt;p&gt;I have on ocassion been exploring the use of &lt;a href=&quot;/tags.html/#semantics&quot;&gt;semantic&lt;/a&gt; markup in the notebook. In this post I illustrate how I am handling semantic citations. One of the more intriguing ideas is the ability to add semantic meaning to citations through the CITO ontology of &lt;span class=&quot;showtooltip&quot; title=&quot;Shotton D (2010). Cito, The Citation Typing Ontology. _Journal
of Biomedical Semantics_, *1*. ISSN 2041-1480, 
http://dx.doi.org/10.1186/2041-1480-1-S1-S6.&quot;&gt;&lt;a href=&quot;http://dx.doi.org/10.1186/2041-1480-1-S1-S6&quot; rel=&quot;http://purl.org/spar/cito/usesMethodIn&quot; &gt;Shotton (2010)&lt;/a&gt;&lt;/span&gt;. Citation counts form a central part of academic discourse, but contain very little information regarding the reason for the citation. Most notably, ‘negative’ citations refuting a claim carry just the same weight as those confirming or relying upon a claim. Given the scale and expansion of academic literature, it is rarely reasonable to explore this citation graph manually. CITO provides a language for embedding the meaning of the citation, such as “discusses”, “refutes”, or “usesMethodIn”, to the citation. (For instance, my earlier citation to Shotton identifies itself as “usesMethodIn”, as I will explain).&lt;/p&gt;
&lt;p&gt;The main barrier to this approach is a lack of adoption. One of the primary concerns is the burden it places on authors of adding the extra data. On one hand, authors already bother formatting and reformatting layout, spelling, and reference order to the arcane specifications of different journals, which suggests authors can be persuaded to do some pretty tedious tasks if the publishers would require it. After all, the task of adding citations is already much easier than it was in the days of paper journals. Still, it is much simpler to remove a tedious requirement than to add a new one. My hope is that intelligent tools can simplify this process, as they already have with other aspects of managing citations, and encourage the use of CITO. In this spirit, I have recently started trying to consistently use the CITO ontology in my notebook entries as a test case, using some tools of my own design.&lt;/p&gt;
&lt;h3 id=&quot;semantics-in-knitcitations&quot;&gt;Semantics in knitcitations&lt;/h3&gt;
&lt;p&gt;Several months ago I created the R package &lt;a href=&quot;https://github.com/cboettig/knitcitations&quot;&gt;knitcitations&lt;/a&gt; to provide a citation platform for &lt;a href=&quot;http://yihui.name/knitr&quot;&gt;knitr&lt;/a&gt; dynamic documents, which provide executable code and automatic inclusion of results inside plain-text (markdown) descriptions. I write most of my research scripts and many of my notebook entries in this manner. The package can generate citations by DOI, circumventing the need for maintaining bibtex or similar database of citation information, using commands such as&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;citet&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;10.1186/2041-1480-1-S1-S6&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Extending the package to support CITO was rather straight forward. Using the latest version of knitcitations, one can generate in-line citations with CITO semantics simply by passing the reason for the citation as well, such as&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;citet&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&amp;quot;10.1186/2041-1480-1-S1-S6&amp;quot;&lt;/span&gt;, &lt;span class=&quot;dt&quot;&gt;cito=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;usesMethodIn&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which generates the following HTML:&lt;/p&gt;
&lt;pre class=&quot;sourceCode html&quot;&gt;&lt;code class=&quot;sourceCode html&quot;&gt;&lt;span class=&quot;kw&quot;&gt;&amp;lt;a&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; href=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;#39;http://dx.doi.org/10.1186/2041-1480-1-S1-S6&amp;#39;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;#39;http://purl.org/spar/cito/usesMethodIn&amp;#39;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;Shotton (2010)&lt;span class=&quot;kw&quot;&gt;&amp;lt;/a&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This provides a convient platform to generate semantic citations in this lab notebook. As before, knitcitations will also generate a complete reference list at the end of the document by calling the &lt;code&gt;bibliography&lt;/code&gt; function at the end.&lt;/p&gt;
&lt;h3 id=&quot;semantic-overkill&quot;&gt;Semantic overkill?&lt;/h3&gt;
&lt;p&gt;It is possible to add far more semantic data to this reference list at the end of an article. Invisible semantic markup can identify to a machine what value corresponds to the volume number or issue number, or journal name, e,g, using the BIBO ontology. I have added support for ths kind of markup to knitcitations as well, and &lt;a href=&quot;/2013/02/12/notes.html&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;/2013/02/21/notes.html&quot;&gt;of&lt;/a&gt; my posts provide examples. The raw markup looks like this:&lt;/p&gt;
&lt;pre class=&quot;sourceCode html&quot;&gt;&lt;code class=&quot;sourceCode html&quot;&gt;&lt;span class=&quot;kw&quot;&gt;&amp;lt;div&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; prefix=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;dc: http://purl.org/dc/terms/,&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;                      bibo: http://purl.org/ontology/bibo/,&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;                      foaf: http://xmlns.com/foaf/spec/,&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;                      biro: http://purl.org/spar/biro/&amp;quot;&lt;/span&gt;
&lt;span class=&quot;ot&quot;&gt;        rel=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;http://purl.org/spar/biro/ReferenceList&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;ul&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; class=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;#39;bibliography&amp;#39;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt; 
&lt;span class=&quot;kw&quot;&gt;&amp;lt;li&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;dc:title&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;Fisheries: Does Catch Reflect Abundance?.&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;dc:creator&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;foaf:givenName&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;Daniel&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;foaf:familyName&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;Pauly&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;, &lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;dc:creator&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;foaf:givenName&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;Ray&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;foaf:familyName&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;Hilborn&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;, &lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;dc:creator&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;foaf:givenName&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;Trevor A.&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;foaf:familyName&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;Branch&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;, &lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;  (&lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;dc:date&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;2013&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;)  &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; rel=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;http://purl.org/dc/terms/isPartOf&amp;quot;&lt;/span&gt; 
&lt;span class=&quot;ot&quot;&gt;                            resource=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;[http://purl.org/dc/terms/journal]&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;http://purl.org/dc/terms/title&amp;quot;&lt;/span&gt;
&lt;span class=&quot;ot&quot;&gt;                                content=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot; Nature &amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;
                          &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;bibo:shortTitle&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt; Nature &lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;
               &lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;  &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;bibo:volume&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;494&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;    &lt;span class=&quot;kw&quot;&gt;&amp;lt;a&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;bibo:doi&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; href=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;http://dx.doi.org/10.1038/494303a&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;10.1038/494303a&lt;span class=&quot;kw&quot;&gt;&amp;lt;/a&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;/li&amp;gt;&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;&amp;lt;li&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;dc:title&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;Net Gains.&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;dc:creator&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;foaf:givenName&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;unknown&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;foaf:familyName&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;unknown&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;, &lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;  (&lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;dc:date&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;2013&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;)  &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; rel=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;http://purl.org/dc/terms/isPartOf&amp;quot;&lt;/span&gt; 
&lt;span class=&quot;ot&quot;&gt;                            resource=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;[http://purl.org/dc/terms/journal]&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;http://purl.org/dc/terms/title&amp;quot;&lt;/span&gt;
&lt;span class=&quot;ot&quot;&gt;                                content=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot; Nature &amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;
                        &lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;
                          &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;bibo:shortTitle&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt; Nature &lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;
               &lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;  &lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;bibo:volume&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;494&lt;span class=&quot;kw&quot;&gt;&amp;lt;/span&amp;gt;&lt;/span&gt;    &lt;span class=&quot;kw&quot;&gt;&amp;lt;a&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;bibo:doi&amp;quot;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; href=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;http://dx.doi.org/10.1038/494282a&amp;quot;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;10.1038/494282a&lt;span class=&quot;kw&quot;&gt;&amp;lt;/a&amp;gt;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;lt;/li&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;kw&quot;&gt;&amp;lt;/ul&amp;gt;&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, I have since decided that such markup is largely overkill. The DOI uniquely identifies the publication already, and allows us to programmatically retrieve the rest of the data (title, authors, journal, etc) from semantically identified XML by querying against services such as CrossRef. &lt;em&gt;This is the essential concept of linked data&lt;/em&gt;, by which both source and referer are enriched.&lt;/p&gt;
&lt;p&gt;Moreover, DOIs follows a specific construction that lets us reliably &lt;a href=&quot;http://stackoverflow.com/questions/27910/finding-a-doi-in-a-document-or-page&quot;&gt;identify them in plain text using regular expressions&lt;/a&gt;, making any futher semantics to declare that we are citing the article mostly irrelevant. This is convient for identifying all citations appearing in the notebook without any markup. The CITO example above has the advantage of providing a link and associating the DOI with the reason for the citation, by virtue of being inside the same html anchor element.&lt;/p&gt;
&lt;h3 id=&quot;replacing-the-reference-list&quot;&gt;Replacing the reference list?&lt;/h3&gt;
&lt;p&gt;If we are not going to semantically mark up the reference list, we could consider abolishing the reference list all together. After all, as a tool for the digital reader the concept is rather vestigal – I hate losing my place by scrolling to the end of an article just to see to what reference number 7 refers. With the method shown thus far, the reader can open the link to access this information, but that still interrupts the flow of reading. The digitally native solution is a mouse-over or tooltip effect that displays this information, as many professional publishers already use in their HTML versions.&lt;/p&gt;
&lt;p&gt;Once again, this is straight forward to support using the knitcitations package, at least for sites that include the popular &lt;a href=&quot;http://twitter.github.com/bootstrap&quot;&gt;bootstrap&lt;/a&gt; javascript libraries, such as this notebook. I have added an option to the in-text citation functions to provide such tooltips in a span element, such that calling the command&lt;/p&gt;
&lt;pre class=&quot;sourceCode html&quot;&gt;&lt;code class=&quot;sourceCode html&quot;&gt;&lt;span class=&quot;kw&quot;&gt;&amp;lt;span&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; class=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;#39;showtooltip&amp;#39;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; title=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;#39;Shotton D (2010). &amp;quot;Cito, The Citation Typing Ontology.&amp;quot; _Journal of&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;Biomedical Semantics_, *1*. ISSN 2041-1480, &lt;/span&gt;&lt;span class=&quot;er&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;URL:&lt;/span&gt;
&lt;span class=&quot;st&quot;&gt;http://dx.doi.org/10.1186/2041-1480-1-S1-S6&amp;gt;.&amp;#39;&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;&amp;gt;&amp;lt;a&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; href=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;#39;http://dx.doi.org/10.1186/2041-1480-1-S1-S6&amp;#39;&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt; property=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;#39;http://purl.org/spar/cito/usesMethodIn&amp;#39;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;&amp;gt;&lt;/span&gt;Shotton (2010)&lt;span class=&quot;kw&quot;&gt;&amp;lt;/a&amp;gt;&amp;lt;/span&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This behavior can be toggled on by calling&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;cite_options&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;tooltip=&lt;/span&gt;&lt;span class=&quot;ot&quot;&gt;TRUE&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;after loading the knitcitations library. &lt;strong&gt;EDIT&lt;/strong&gt;: Note that this requires the javascript trigger on the class &lt;code&gt;showtooltip&lt;/code&gt;, which can be done by adding this to your header:&lt;/p&gt;
&lt;pre class=&quot;js&quot;&gt;&lt;code&gt;    &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
      $(document).ready(function (){
        $(&amp;quot;.showtooltip&amp;quot;).tooltip();
      });
    &amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;citing-without-dois&quot;&gt;Citing without DOIs&lt;/h3&gt;
&lt;p&gt;Not all the literature we may wish to cite includes DOIs, such as &lt;a href=&quot;http://arxiv.org&quot;&gt;arXiv&lt;/a&gt; preprints, Wikipedia pages, or other academic blogs. Even when a DOI is present it is not always trivial to locate. With version 0.4-0, knitcitations can produce citations given any URL using the &lt;a href=&quot;http://greycite.knowledgeblog.org&quot;&gt;Greycite API&lt;/a&gt; (&lt;span class=&quot;showtooltip&quot; title=&quot;Lord P (2012). Greycite. 
http://knowledgeblog.org/greycite [Online. last-accessed:
2012-10-10 13:36:24].  http://knowledgeblog.org/greycite.&quot;&gt;&lt;a href=&quot;http://knowledgeblog.org/greycite&quot; rel=&quot;http://purl.org/spar/cito/usesMethodIn&quot; &gt;Lord, 2012&lt;/a&gt;&lt;/span&gt;). For instance, this citation is created with the command &lt;code&gt;citep(&amp;quot;http://knowledgeblog.org/greycite&amp;quot;, cito=&amp;quot;usesMethodIn&amp;quot;)&lt;/code&gt;.&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
